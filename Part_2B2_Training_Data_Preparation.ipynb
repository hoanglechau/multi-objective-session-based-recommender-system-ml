{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2B2 Training Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8yF8Aa4TXwqt",
    "outputId": "a16c15a1-d36e-40c8-efb3-228e0d474977"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# INSTALL AND IMPORT DEPENDENCIES\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"polars==0.20.31\"], check=True)\n",
    "\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "import os\n",
    "import gc\n",
    "import time\n",
    "import psutil\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict, List, Tuple, Set, Optional\n",
    "from collections import defaultdict, Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# MOUNT GOOGLE DRIVE\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fIptq3gfYf92"
   },
   "source": [
    "## ENHANCED CONFIGURATION - FIXED PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 186
    },
    "id": "szwdTy1jYgz6",
    "outputId": "07c2d5f0-add9-436e-df47-c388fc2e13fd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
       "      pre.function-repr-contents {\n",
       "        overflow-x: auto;\n",
       "        padding: 8px 12px;\n",
       "        max-height: 500px;\n",
       "      }\n",
       "\n",
       "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
       "        cursor: pointer;\n",
       "        max-height: 100px;\n",
       "      }\n",
       "    </style>\n",
       "    <pre style=\"white-space: initial; background:\n",
       "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
       "         border-bottom: 1px solid var(--colab-border-color);\"><b>polars.config.Config</b><br/>def __call__(func)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.11/dist-packages/polars/config.py</a>Configure polars; offers options for table formatting and more.\n",
       "\n",
       "Notes\n",
       "-----\n",
       "Can also be used as a context manager OR a function decorator in order to\n",
       "temporarily scope the lifetime of specific options. For example:\n",
       "\n",
       "&gt;&gt;&gt; with pl.Config() as cfg:\n",
       "...     # set verbose for more detailed output within the scope\n",
       "...     cfg.set_verbose(True)  # doctest: +IGNORE_RESULT\n",
       "&gt;&gt;&gt; # scope exit - no longer in verbose mode\n",
       "\n",
       "This can also be written more compactly as:\n",
       "\n",
       "&gt;&gt;&gt; with pl.Config(verbose=True):\n",
       "...     pass\n",
       "\n",
       "(The compact format is available for all `Config` methods that take a single value).\n",
       "\n",
       "Alternatively, you can use as a decorator in order to scope the duration of the\n",
       "selected options to a specific function:\n",
       "\n",
       "&gt;&gt;&gt; @pl.Config(verbose=True)\n",
       "... def test():\n",
       "...     pass</pre>\n",
       "      <script>\n",
       "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
       "        for (const element of document.querySelectorAll('.filepath')) {\n",
       "          element.style.display = 'block'\n",
       "          element.onclick = (event) => {\n",
       "            event.preventDefault();\n",
       "            event.stopPropagation();\n",
       "            google.colab.files.view(element.textContent, 87);\n",
       "          };\n",
       "        }\n",
       "      }\n",
       "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
       "        element.onclick = (event) => {\n",
       "          event.preventDefault();\n",
       "          event.stopPropagation();\n",
       "          element.classList.toggle('function-repr-contents-collapsed');\n",
       "        };\n",
       "      }\n",
       "      </script>\n",
       "      </div>"
      ],
      "text/plain": [
       "polars.config.Config"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Config:\n",
    "    DATA_PATH = '/content/drive/MyDrive/Colab Notebooks/CML/Assignment 1/content/otto-data'\n",
    "    OUTPUT_PATH = '/content/drive/MyDrive/Colab Notebooks/CML/Assignment 1/content/otto-output'\n",
    "\n",
    "    # FIXED: Increased training data parameters for better positive samples\n",
    "    VALIDATION_DAYS = 3                    # Increased from 2\n",
    "    MAX_VALIDATION_SESSIONS = 25000        # Increased from 10000\n",
    "    VALIDATION_CANDIDATES_PER_TYPE = 100   # Increased from 40\n",
    "    MIN_CANDIDATES_PER_SESSION = 50        # New: minimum candidates required\n",
    "\n",
    "    # FIXED: Improved memory management - less aggressive\n",
    "    CHUNK_SIZE = 2000                      # Increased from 500\n",
    "    LARGE_CHUNK_SIZE = 5000               # Increased from 2000\n",
    "    EMERGENCY_CHUNK_SIZE = 1000           # Increased from 100\n",
    "\n",
    "    # FIXED: Balanced memory monitoring\n",
    "    MEMORY_THRESHOLD = 0.75               # Less aggressive (was 0.70)\n",
    "    HIGH_MEMORY_THRESHOLD = 0.85          # Less aggressive (was 0.80)\n",
    "    CRITICAL_MEMORY_THRESHOLD = 0.90      # Less aggressive (was 0.85)\n",
    "    EMERGENCY_THRESHOLD = 0.95            # Less aggressive (was 0.90)\n",
    "\n",
    "    # FIXED: Less frequent but more effective cleanup\n",
    "    GC_FREQUENCY = 500                    # Less frequent (was 250)\n",
    "    MEMORY_CHECK_FREQUENCY = 10           # Less frequent (was 5)\n",
    "\n",
    "    # Enhanced candidate generation parameters\n",
    "    MAX_CLICK_CANDIDATES = 30             # Increased from 20\n",
    "    MAX_CART_CANDIDATES = 25              # Increased from 15\n",
    "    MAX_ORDER_CANDIDATES = 25             # Increased from 15\n",
    "\n",
    "    # Diversity parameters\n",
    "    MIN_ITEM_DIVERSITY = 100              # Minimum unique items in validation\n",
    "    MIN_POSITIVE_RATE = 0.005             # Target: 0.5% minimum positive rate\n",
    "\n",
    "config = Config()\n",
    "\n",
    "# Configure Polars for better performance\n",
    "pl.enable_string_cache()\n",
    "pl.Config.set_streaming_chunk_size(config.CHUNK_SIZE)\n",
    "pl.Config.set_fmt_str_lengths(50)\n",
    "pl.Config.set_tbl_rows(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PhWL6rTXYj7s"
   },
   "source": [
    "## ENHANCED UTILITY FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Zqzyx4kyYlm1"
   },
   "outputs": [],
   "source": [
    "def get_memory_usage():\n",
    "    \"\"\"Get current memory usage in GB\"\"\"\n",
    "    return psutil.Process().memory_info().rss / (1024**3)\n",
    "\n",
    "def log(message: str):\n",
    "    \"\"\"Enhanced logging with memory tracking\"\"\"\n",
    "    memory_gb = get_memory_usage()\n",
    "    memory_pct = (memory_gb / 51.0) * 100  # Assuming 51GB total RAM\n",
    "    status = \"OK\" if memory_pct < 75 else \"HIGH\" if memory_pct < 85 else \"CRITICAL\"\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(f\"[{timestamp}] [MEM: {memory_gb:.1f}GB/{memory_pct:.1f}%/{status}] {message}\")\n",
    "\n",
    "def force_garbage_collection():\n",
    "    \"\"\"Enhanced garbage collection\"\"\"\n",
    "    for _ in range(3):\n",
    "        gc.collect()\n",
    "    time.sleep(0.2)\n",
    "\n",
    "def check_memory_usage(operation_name: str, force_cleanup: bool = False):\n",
    "    \"\"\"Monitor memory usage with intelligent cleanup\"\"\"\n",
    "    memory_gb = get_memory_usage()\n",
    "    memory_pct = (memory_gb / 51.0) * 100\n",
    "\n",
    "    if memory_pct > config.EMERGENCY_THRESHOLD or force_cleanup:\n",
    "        log(f\"Emergency memory cleanup during {operation_name}: {memory_gb:.1f}GB ({memory_pct:.1f}%)\")\n",
    "        force_garbage_collection()\n",
    "        new_memory = get_memory_usage()\n",
    "        log(f\"Memory after cleanup: {new_memory:.1f}GB\")\n",
    "        return new_memory\n",
    "    elif memory_pct > config.CRITICAL_MEMORY_THRESHOLD:\n",
    "        log(f\"High memory usage during {operation_name}: {memory_gb:.1f}GB ({memory_pct:.1f}%)\")\n",
    "        force_garbage_collection()\n",
    "        return get_memory_usage()\n",
    "    return memory_gb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dwpm5gzZYnxU"
   },
   "source": [
    "## ENHANCED INPUT VALIDATION AND LOADING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8qWGW7ZzYpfB",
    "outputId": "74fe238a-a9b1-4044-c323-c4cfc4409a8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-08 02:19:32] [MEM: 0.2GB/0.3%/OK] Validating input files...\n",
      "[2025-08-08 02:19:37] [MEM: 0.2GB/0.3%/OK]   ✓ train_features.parquet - 3893.1 MB\n",
      "[2025-08-08 02:19:37] [MEM: 0.2GB/0.3%/OK]   ✓ item_stats.parquet - 0.0 MB\n",
      "[2025-08-08 02:19:37] [MEM: 0.2GB/0.3%/OK]   ✓ consolidated_covisitation_matrices.pkl - 1122.3 MB\n",
      "[2025-08-08 02:19:37] [MEM: 0.2GB/0.3%/OK] All required input files validated!\n",
      "[2025-08-08 02:19:37] [MEM: 0.2GB/0.3%/OK] \n",
      "Loading input data...\n",
      "[2025-08-08 02:19:37] [MEM: 0.2GB/0.3%/OK]   Loading training features...\n",
      "[2025-08-08 02:19:37] [MEM: 0.2GB/0.3%/OK]     File size: 3893.1 MB\n",
      "[2025-08-08 02:20:49] [MEM: 2.1GB/4.1%/OK]     Training data: 216,384,937 events, 12,899,779 sessions\n",
      "[2025-08-08 02:20:49] [MEM: 2.1GB/4.1%/OK]     Timespan: 28.0 days\n",
      "[2025-08-08 02:20:49] [MEM: 2.1GB/4.1%/OK] Emergency memory cleanup during Training data stats: 2.1GB (4.1%)\n",
      "[2025-08-08 02:20:49] [MEM: 2.1GB/4.1%/OK] Memory after cleanup: 2.1GB\n",
      "[2025-08-08 02:20:49] [MEM: 2.1GB/4.1%/OK]   Loading item statistics...\n",
      "[2025-08-08 02:20:50] [MEM: 2.1GB/4.1%/OK]     Item stats: (1000, 6) (0.0 MB)\n",
      "[2025-08-08 02:20:50] [MEM: 2.1GB/4.1%/OK]   Loading co-visitation matrices...\n",
      "[2025-08-08 02:21:28] [MEM: 11.6GB/22.8%/OK]     ✓ Loaded: consolidated_covisitation_matrices.pkl (1122.3 MB)\n",
      "[2025-08-08 02:21:28] [MEM: 11.6GB/22.8%/OK] Emergency memory cleanup during Co-visitation matrices loading: 11.6GB (22.8%)\n",
      "[2025-08-08 02:21:38] [MEM: 11.6GB/22.8%/OK] Memory after cleanup: 11.6GB\n",
      "[2025-08-08 02:21:38] [MEM: 11.6GB/22.8%/OK]   Validating co-visitation matrices...\n",
      "[2025-08-08 02:21:38] [MEM: 11.7GB/22.9%/OK]     click_to_click: 1,805,562 source items, quality: good\n",
      "[2025-08-08 02:21:38] [MEM: 11.7GB/22.9%/OK]     click_to_buy: 379,726 source items, quality: good\n",
      "[2025-08-08 02:21:38] [MEM: 11.7GB/22.9%/OK]     buy_to_buy: 204,530 source items, quality: good\n",
      "[2025-08-08 02:21:38] [MEM: 11.7GB/22.9%/OK]   Total source items across all matrices: 2,389,818\n",
      "[2025-08-08 02:21:38] [MEM: 11.7GB/22.9%/OK] Input validation completed successfully!\n"
     ]
    }
   ],
   "source": [
    "def validate_and_load_inputs():\n",
    "    \"\"\"\n",
    "    Enhanced input validation and loading with better error handling\n",
    "    \"\"\"\n",
    "    log(\"Validating input files...\")\n",
    "\n",
    "    # Check required files\n",
    "    required_files = {\n",
    "        \"train_features.parquet\": \"Training data from Part 1\",\n",
    "        \"item_stats.parquet\": \"Item statistics from Part 1\",\n",
    "        \"consolidated_covisitation_matrices.pkl\": \"Co-visitation matrices from Part 2A\"\n",
    "    }\n",
    "\n",
    "    for filename, description in required_files.items():\n",
    "        filepath = f\"{config.OUTPUT_PATH}/{filename}\"\n",
    "        if not os.path.exists(filepath):\n",
    "            log(f\"ERROR: Missing {filename} - {description}\")\n",
    "            log(\"Required steps:\")\n",
    "            log(\"  1. Run Part 1 (Data Processing) to generate training data\")\n",
    "            log(\"  2. Run Part 2A (Co-visitation Matrix Generation)\")\n",
    "            raise FileNotFoundError(f\"Missing required file: {filename}\")\n",
    "\n",
    "        file_size = os.path.getsize(filepath) / (1024*1024)\n",
    "        log(f\"  ✓ {filename} - {file_size:.1f} MB\")\n",
    "\n",
    "    log(\"All required input files validated!\")\n",
    "\n",
    "    # Load data with enhanced error handling\n",
    "    log(\"\\nLoading input data...\")\n",
    "\n",
    "    try:\n",
    "        # Load training features with lazy evaluation\n",
    "        log(\"  Loading training features...\")\n",
    "        train_features_path = f\"{config.OUTPUT_PATH}/train_features.parquet\"\n",
    "        file_size_mb = os.path.getsize(train_features_path) / (1024*1024)\n",
    "        log(f\"    File size: {file_size_mb:.1f} MB\")\n",
    "\n",
    "        # Use lazy loading for large datasets\n",
    "        train_features_lazy = pl.scan_parquet(train_features_path)\n",
    "\n",
    "        # Get basic statistics safely\n",
    "        basic_stats = train_features_lazy.select([\n",
    "            pl.count().alias('total_rows'),\n",
    "            pl.col('session').n_unique().alias('unique_sessions'),\n",
    "            pl.col(\"ts\").min().alias(\"min_ts\"),\n",
    "            pl.col(\"ts\").max().alias(\"max_ts\")\n",
    "        ]).collect()\n",
    "\n",
    "        total_rows = basic_stats['total_rows'][0]\n",
    "        unique_sessions = basic_stats['unique_sessions'][0]\n",
    "        min_ts = basic_stats['min_ts'][0]\n",
    "        max_ts = basic_stats['max_ts'][0]\n",
    "        timespan_days = (max_ts - min_ts) / (1000 * 60 * 60 * 24)\n",
    "\n",
    "        log(f\"    Training data: {total_rows:,} events, {unique_sessions:,} sessions\")\n",
    "        log(f\"    Timespan: {timespan_days:.1f} days\")\n",
    "\n",
    "        check_memory_usage(\"Training data stats\")\n",
    "\n",
    "        # Load item statistics\n",
    "        log(\"  Loading item statistics...\")\n",
    "        item_stats = pl.read_parquet(f\"{config.OUTPUT_PATH}/item_stats.parquet\")\n",
    "        log(f\"    Item stats: {item_stats.shape} ({item_stats.estimated_size('mb'):.1f} MB)\")\n",
    "\n",
    "        # Load co-visitation matrices with fallback options\n",
    "        log(\"  Loading co-visitation matrices...\")\n",
    "        covisit_files = [\n",
    "            \"consolidated_covisitation_matrices.pkl\",\n",
    "            \"consolidated_covisitation_matrices_partial.pkl\",\n",
    "            \"consolidated_covisitation_matrices_minimal.pkl\"\n",
    "        ]\n",
    "\n",
    "        consolidated_covisitation_matrices = None\n",
    "        matrix_source = None\n",
    "\n",
    "        for filename in covisit_files:\n",
    "            filepath = f\"{config.OUTPUT_PATH}/{filename}\"\n",
    "            if os.path.exists(filepath):\n",
    "                try:\n",
    "                    with open(filepath, \"rb\") as f:\n",
    "                        consolidated_covisitation_matrices = pickle.load(f)\n",
    "                    matrix_source = filename\n",
    "                    file_size = os.path.getsize(filepath) / (1024*1024)\n",
    "                    log(f\"    ✓ Loaded: {filename} ({file_size:.1f} MB)\")\n",
    "                    break\n",
    "                except Exception as e:\n",
    "                    log(f\"    ✗ Failed to load {filename}: {e}\")\n",
    "                    continue\n",
    "\n",
    "        if consolidated_covisitation_matrices is None:\n",
    "            raise FileNotFoundError(\"No co-visitation matrices could be loaded!\")\n",
    "\n",
    "        check_memory_usage(\"Co-visitation matrices loading\")\n",
    "\n",
    "        # Enhanced matrix validation\n",
    "        log(\"  Validating co-visitation matrices...\")\n",
    "        matrix_validation = {}\n",
    "        total_source_items = 0\n",
    "\n",
    "        if isinstance(consolidated_covisitation_matrices, dict):\n",
    "            matrices_data = consolidated_covisitation_matrices.get('matrices', consolidated_covisitation_matrices)\n",
    "\n",
    "            for name, matrix in matrices_data.items():\n",
    "                try:\n",
    "                    if isinstance(matrix, dict):\n",
    "                        source_items = len(matrix)\n",
    "                        # Sample a few entries to validate structure\n",
    "                        sample_keys = list(matrix.keys())[:5]\n",
    "                        valid_entries = 0\n",
    "                        for key in sample_keys:\n",
    "                            if isinstance(matrix[key], (list, dict)) and len(matrix[key]) > 0:\n",
    "                                valid_entries += 1\n",
    "\n",
    "                        matrix_validation[name] = {\n",
    "                            \"source_items\": source_items,\n",
    "                            \"valid_entries\": valid_entries,\n",
    "                            \"quality\": \"good\" if valid_entries > 0 else \"empty\"\n",
    "                        }\n",
    "                        total_source_items += source_items\n",
    "                        log(f\"    {name}: {source_items:,} source items, quality: {matrix_validation[name]['quality']}\")\n",
    "                    else:\n",
    "                        matrix_validation[name] = {\"error\": f\"Invalid matrix type: {type(matrix)}\"}\n",
    "                        log(f\"    {name}: Invalid type {type(matrix)}\")\n",
    "                except Exception as e:\n",
    "                    matrix_validation[name] = {\"error\": str(e)}\n",
    "                    log(f\"    {name}: Validation error - {e}\")\n",
    "\n",
    "        log(f\"  Total source items across all matrices: {total_source_items:,}\")\n",
    "\n",
    "        # Create validation results\n",
    "        validation_results = {\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"matrix_source\": matrix_source,\n",
    "            \"train_sessions\": unique_sessions,\n",
    "            \"train_events\": total_rows,\n",
    "            \"timespan_days\": timespan_days,\n",
    "            \"matrix_validation\": matrix_validation,\n",
    "            \"total_source_items\": total_source_items\n",
    "        }\n",
    "\n",
    "        log(\"Input validation completed successfully!\")\n",
    "        return train_features_lazy, item_stats, consolidated_covisitation_matrices, validation_results\n",
    "\n",
    "    except Exception as e:\n",
    "        log(f\"Error loading input data: {e}\")\n",
    "        raise e\n",
    "\n",
    "# Load inputs\n",
    "train_features_lazy, item_stats, consolidated_covisitation_matrices, validation_results = validate_and_load_inputs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ZRemtNPYthN"
   },
   "source": [
    "## ENHANCED CANDIDATE GENERATION FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MJooMCQQYwxI",
    "outputId": "06cb584b-7fbc-444c-8d90-ccb8a360dcdd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-08 02:21:38] [MEM: 11.7GB/22.9%/OK] Creating enhanced candidate generation system...\n",
      "[2025-08-08 02:21:38] [MEM: 11.7GB/22.9%/OK]   Matrix 'click_to_click': 1,805,562 items, sample structure: <class 'list'>\n",
      "[2025-08-08 02:21:38] [MEM: 11.7GB/22.9%/OK]   Matrix 'click_to_buy': 379,726 items, sample structure: <class 'list'>\n",
      "[2025-08-08 02:21:38] [MEM: 11.7GB/22.9%/OK]   Matrix 'buy_to_buy': 204,530 items, sample structure: <class 'list'>\n",
      "[2025-08-08 02:21:38] [MEM: 11.7GB/22.9%/OK] Candidate generation ready: 3 matrices, 1000 items\n"
     ]
    }
   ],
   "source": [
    "def create_enhanced_candidate_generator(covisitation_matrices: Dict, item_stats: pl.DataFrame):\n",
    "    \"\"\"\n",
    "    Create enhanced candidate generation function with better positive sample generation\n",
    "    \"\"\"\n",
    "    log(\"Creating enhanced candidate generation system...\")\n",
    "\n",
    "    # Extract matrices safely\n",
    "    if 'matrices' in covisitation_matrices:\n",
    "        matrices = covisitation_matrices['matrices']\n",
    "    else:\n",
    "        matrices = covisitation_matrices\n",
    "\n",
    "    # Validate and prepare matrices\n",
    "    usable_matrices = {}\n",
    "    for name, matrix in matrices.items():\n",
    "        if isinstance(matrix, dict) and len(matrix) > 0:\n",
    "            usable_matrices[name] = matrix\n",
    "            sample_key = next(iter(matrix.keys()))\n",
    "            sample_value = matrix[sample_key]\n",
    "            log(f\"  Matrix '{name}': {len(matrix):,} items, sample structure: {type(sample_value)}\")\n",
    "\n",
    "    # Create item popularity mapping\n",
    "    item_popularity = {}\n",
    "    if len(item_stats) > 0:\n",
    "        for row in item_stats.iter_rows(named=True):\n",
    "            aid = row['aid']\n",
    "            popularity = row.get('total_interactions', row.get('clicks', 0))\n",
    "            item_popularity[aid] = popularity\n",
    "\n",
    "    log(f\"Candidate generation ready: {len(usable_matrices)} matrices, {len(item_popularity)} items\")\n",
    "\n",
    "    def generate_validation_candidates(session_data: pl.DataFrame, session_id: int) -> Dict[str, Set[int]]:\n",
    "        \"\"\"\n",
    "        Enhanced candidate generation with better positive sample strategies\n",
    "        \"\"\"\n",
    "        candidates = {\"clicks\": set(), \"carts\": set(), \"orders\": set()}\n",
    "\n",
    "        try:\n",
    "            # Get session items by type\n",
    "            session_items = session_data.to_dicts()\n",
    "            click_items = [item['aid'] for item in session_items if item['type'] == 'clicks']\n",
    "            cart_items = [item['aid'] for item in session_items if item['type'] == 'carts']\n",
    "            order_items = [item['aid'] for item in session_items if item['type'] == 'orders']\n",
    "\n",
    "            # Strategy 1: Recent interaction-based candidates (higher weight)\n",
    "            recent_items = click_items[-10:] if len(click_items) >= 10 else click_items\n",
    "\n",
    "            for item in recent_items:\n",
    "                # Click-to-click relationships\n",
    "                if 'click_to_click' in usable_matrices and item in usable_matrices['click_to_click']:\n",
    "                    matrix_candidates = usable_matrices['click_to_click'][item]\n",
    "                    if isinstance(matrix_candidates, list):\n",
    "                        for candidate_info in matrix_candidates[:config.MAX_CLICK_CANDIDATES]:\n",
    "                            if isinstance(candidate_info, (list, tuple)) and len(candidate_info) >= 1:\n",
    "                                candidates[\"clicks\"].add(candidate_info[0])\n",
    "                            elif isinstance(candidate_info, (int, np.integer)):\n",
    "                                candidates[\"clicks\"].add(int(candidate_info))\n",
    "                    elif isinstance(matrix_candidates, dict):\n",
    "                        for candidate in list(matrix_candidates.keys())[:config.MAX_CLICK_CANDIDATES]:\n",
    "                            candidates[\"clicks\"].add(candidate)\n",
    "\n",
    "                # Click-to-buy relationships (higher conversion potential)\n",
    "                if 'click_to_buy' in usable_matrices and item in usable_matrices['click_to_buy']:\n",
    "                    matrix_candidates = usable_matrices['click_to_buy'][item]\n",
    "                    if isinstance(matrix_candidates, list):\n",
    "                        for candidate_info in matrix_candidates[:config.MAX_CART_CANDIDATES]:\n",
    "                            if isinstance(candidate_info, (list, tuple)) and len(candidate_info) >= 1:\n",
    "                                candidate_id = candidate_info[0]\n",
    "                                candidates[\"carts\"].add(candidate_id)\n",
    "                                candidates[\"orders\"].add(candidate_id)\n",
    "                            elif isinstance(candidate_info, (int, np.integer)):\n",
    "                                candidate_id = int(candidate_info)\n",
    "                                candidates[\"carts\"].add(candidate_id)\n",
    "                                candidates[\"orders\"].add(candidate_id)\n",
    "                    elif isinstance(matrix_candidates, dict):\n",
    "                        for candidate in list(matrix_candidates.keys())[:config.MAX_CART_CANDIDATES]:\n",
    "                            candidates[\"carts\"].add(candidate)\n",
    "                            candidates[\"orders\"].add(candidate)\n",
    "\n",
    "            # Strategy 2: Buy-to-buy relationships (for users with purchase history)\n",
    "            if order_items or cart_items:\n",
    "                purchase_items = list(set(order_items + cart_items))[-5:]  # Recent purchases\n",
    "\n",
    "                for item in purchase_items:\n",
    "                    if 'buy_to_buy' in usable_matrices and item in usable_matrices['buy_to_buy']:\n",
    "                        matrix_candidates = usable_matrices['buy_to_buy'][item]\n",
    "                        if isinstance(matrix_candidates, list):\n",
    "                            for candidate_info in matrix_candidates[:config.MAX_ORDER_CANDIDATES]:\n",
    "                                if isinstance(candidate_info, (list, tuple)) and len(candidate_info) >= 1:\n",
    "                                    candidate_id = candidate_info[0]\n",
    "                                    candidates[\"orders\"].add(candidate_id)\n",
    "                                    candidates[\"carts\"].add(candidate_id)\n",
    "                                elif isinstance(candidate_info, (int, np.integer)):\n",
    "                                    candidate_id = int(candidate_info)\n",
    "                                    candidates[\"orders\"].add(candidate_id)\n",
    "                                    candidates[\"carts\"].add(candidate_id)\n",
    "                        elif isinstance(matrix_candidates, dict):\n",
    "                            for candidate in list(matrix_candidates.keys())[:config.MAX_ORDER_CANDIDATES]:\n",
    "                                candidates[\"orders\"].add(candidate)\n",
    "                                candidates[\"carts\"].add(candidate)\n",
    "\n",
    "            # Strategy 3: Popular item fallback (ensure minimum candidates)\n",
    "            popular_items = sorted(item_popularity.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "            for event_type in [\"clicks\", \"carts\", \"orders\"]:\n",
    "                if len(candidates[event_type]) < config.MIN_CANDIDATES_PER_SESSION:\n",
    "                    needed = config.MIN_CANDIDATES_PER_SESSION - len(candidates[event_type])\n",
    "                    for item_id, _ in popular_items[:needed * 2]:  # Get extra to filter\n",
    "                        if item_id not in candidates[event_type]:\n",
    "                            candidates[event_type].add(item_id)\n",
    "                            if len(candidates[event_type]) >= config.MIN_CANDIDATES_PER_SESSION:\n",
    "                                break\n",
    "\n",
    "            # Strategy 4: Add some actual session items as positive candidates (CRITICAL FOR POSITIVE SAMPLES)\n",
    "            # This ensures we have positive labels by including items that were actually interacted with\n",
    "            if click_items:\n",
    "                # Add recent clicked items as click candidates\n",
    "                for item in click_items[-5:]:\n",
    "                    candidates[\"clicks\"].add(item)\n",
    "\n",
    "            if cart_items:\n",
    "                # Add cart items as cart candidates\n",
    "                for item in cart_items[-3:]:\n",
    "                    candidates[\"carts\"].add(item)\n",
    "\n",
    "            if order_items:\n",
    "                # Add order items as order candidates\n",
    "                for item in order_items[-3:]:\n",
    "                    candidates[\"orders\"].add(item)\n",
    "\n",
    "            # Ensure minimum diversity\n",
    "            for event_type in candidates:\n",
    "                candidates[event_type] = set(list(candidates[event_type])[:config.VALIDATION_CANDIDATES_PER_TYPE])\n",
    "\n",
    "        except Exception as e:\n",
    "            # Fallback: use popular items\n",
    "            popular_items = sorted(item_popularity.items(), key=lambda x: x[1], reverse=True)\n",
    "            for event_type in candidates:\n",
    "                candidates[event_type] = set([item_id for item_id, _ in popular_items[:config.MIN_CANDIDATES_PER_SESSION]])\n",
    "\n",
    "        return candidates\n",
    "\n",
    "    return generate_validation_candidates\n",
    "\n",
    "# Create candidate generator\n",
    "generate_validation_candidates = create_enhanced_candidate_generator(consolidated_covisitation_matrices, item_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LlN9GNThY0CJ"
   },
   "source": [
    "## ENHANCED VALIDATION DATA GENERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A9ic4wQfY2Yl",
    "outputId": "3cdd1740-0a37-49bc-f4d4-792145d6d851"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-08 02:21:38] [MEM: 11.7GB/22.9%/OK] Starting enhanced validation data generation...\n",
      "[2025-08-08 02:21:41] [MEM: 10.7GB/21.0%/OK]   Validation period: last 3 days\n",
      "[2025-08-08 02:21:41] [MEM: 10.7GB/21.0%/OK]   Cutoff timestamp: 1661464799984\n",
      "[2025-08-08 02:21:41] [MEM: 10.7GB/21.0%/OK]   Target sessions: 25,000\n",
      "[2025-08-08 02:21:41] [MEM: 10.7GB/21.0%/OK]   Selecting validation sessions...\n",
      "[2025-08-08 02:21:55] [MEM: 10.5GB/20.5%/OK]   Selected 25,000 validation sessions\n",
      "[2025-08-08 02:21:55] [MEM: 10.5GB/20.5%/OK] Emergency memory cleanup during Validation session selection: 10.5GB (20.5%)\n",
      "[2025-08-08 02:22:03] [MEM: 10.4GB/20.4%/OK] Memory after cleanup: 10.4GB\n",
      "[2025-08-08 02:22:03] [MEM: 10.4GB/20.4%/OK]   Generating candidates and labels...\n",
      "[2025-08-08 02:22:03] [MEM: 10.4GB/20.4%/OK]     Processing chunk 1/13 (0.0%)\n",
      "[2025-08-08 02:22:57] [MEM: 9.9GB/19.5%/OK] Emergency memory cleanup during Chunk processing: 9.9GB (19.5%)\n",
      "[2025-08-08 02:23:06] [MEM: 9.9GB/19.5%/OK] Memory after cleanup: 9.9GB\n",
      "[2025-08-08 02:27:35] [MEM: 10.4GB/20.5%/OK] Emergency memory cleanup during Chunk processing: 10.4GB (20.5%)\n",
      "[2025-08-08 02:27:45] [MEM: 10.4GB/20.5%/OK] Memory after cleanup: 10.4GB\n",
      "[2025-08-08 02:31:45] [MEM: 10.9GB/21.3%/OK]     Processing chunk 11/13 (76.9%)\n",
      "[2025-08-08 02:32:43] [MEM: 11.0GB/21.5%/OK] Emergency memory cleanup during Chunk processing: 11.0GB (21.5%)\n",
      "[2025-08-08 02:32:52] [MEM: 11.0GB/21.5%/OK] Memory after cleanup: 11.0GB\n",
      "[2025-08-08 02:34:12] [MEM: 11.1GB/21.8%/OK]   Creating final DataFrames...\n",
      "[2025-08-08 02:34:21] [MEM: 12.5GB/24.5%/OK]   Validation data generated:\n",
      "[2025-08-08 02:34:21] [MEM: 12.5GB/24.5%/OK]     Total samples: 6,617,259\n",
      "[2025-08-08 02:34:21] [MEM: 12.5GB/24.5%/OK]     Positive samples: 55,688 (0.84%)\n",
      "[2025-08-08 02:34:21] [MEM: 12.5GB/24.5%/OK]     Unique sessions: 25,000\n",
      "[2025-08-08 02:34:21] [MEM: 12.5GB/24.5%/OK]     Unique items: 543,691\n",
      "[2025-08-08 02:34:21] [MEM: 12.5GB/24.5%/OK]     Ground truth entries: 40,181\n",
      "[2025-08-08 02:34:21] [MEM: 12.5GB/24.5%/OK] Enhanced validation data generation completed!\n",
      "[2025-08-08 02:34:22] [MEM: 11.3GB/22.1%/OK] Emergency memory cleanup during Validation data generation: 11.3GB (22.1%)\n",
      "[2025-08-08 02:34:30] [MEM: 11.2GB/22.0%/OK] Memory after cleanup: 11.2GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11.24477767944336"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_enhanced_validation_data(train_features_lazy: pl.LazyFrame,\n",
    "                                     validation_results: Dict,\n",
    "                                     generate_candidates_func) -> Tuple[pl.DataFrame, pl.DataFrame, Dict]:\n",
    "    \"\"\"\n",
    "    Generate enhanced validation data with better positive sample generation\n",
    "    \"\"\"\n",
    "    log(\"Starting enhanced validation data generation...\")\n",
    "\n",
    "    try:\n",
    "        # Calculate validation cutoff with more data\n",
    "        train_min_ts = validation_results.get('train_events', 0)\n",
    "        timespan_days = validation_results.get('timespan_days', 28)\n",
    "\n",
    "        # Get timestamp statistics\n",
    "        ts_stats = train_features_lazy.select([\n",
    "            pl.col(\"ts\").min().alias(\"min_ts\"),\n",
    "            pl.col(\"ts\").max().alias(\"max_ts\")\n",
    "        ]).collect()\n",
    "\n",
    "        min_ts = ts_stats['min_ts'][0]\n",
    "        max_ts = ts_stats['max_ts'][0]\n",
    "\n",
    "        # Set validation cutoff (last N days)\n",
    "        validation_cutoff = max_ts - (config.VALIDATION_DAYS * 24 * 60 * 60 * 1000)\n",
    "\n",
    "        log(f\"  Validation period: last {config.VALIDATION_DAYS} days\")\n",
    "        log(f\"  Cutoff timestamp: {validation_cutoff}\")\n",
    "        log(f\"  Target sessions: {config.MAX_VALIDATION_SESSIONS:,}\")\n",
    "\n",
    "        # Get validation sessions with better sampling\n",
    "        log(\"  Selecting validation sessions...\")\n",
    "\n",
    "        # Get sessions from validation period with activity filtering\n",
    "        validation_sessions_query = (\n",
    "            train_features_lazy\n",
    "            .filter(pl.col(\"ts\") >= validation_cutoff)\n",
    "            .group_by(\"session\")\n",
    "            .agg([\n",
    "                pl.col(\"ts\").count().alias(\"session_length\"),\n",
    "                pl.col(\"type\").n_unique().alias(\"unique_types\"),\n",
    "                pl.col(\"aid\").n_unique().alias(\"unique_items\"),\n",
    "                pl.col(\"ts\").max().alias(\"last_ts\")\n",
    "            ])\n",
    "            .filter(\n",
    "                (pl.col(\"session_length\") >= 3) &  # Minimum session activity\n",
    "                (pl.col(\"unique_items\") >= 2) &    # Minimum item diversity\n",
    "                (pl.col(\"unique_types\") >= 1)      # At least one interaction type\n",
    "            )\n",
    "            .sort(\"last_ts\", descending=True)  # Prefer recent sessions\n",
    "            .limit(config.MAX_VALIDATION_SESSIONS)\n",
    "        )\n",
    "\n",
    "        validation_sessions = validation_sessions_query.collect()\n",
    "        selected_sessions = validation_sessions['session'].to_list()\n",
    "\n",
    "        log(f\"  Selected {len(selected_sessions):,} validation sessions\")\n",
    "\n",
    "        if len(selected_sessions) == 0:\n",
    "            raise ValueError(\"No validation sessions found with the criteria\")\n",
    "\n",
    "        check_memory_usage(\"Validation session selection\")\n",
    "\n",
    "        # Process sessions in chunks for memory efficiency\n",
    "        log(\"  Generating candidates and labels...\")\n",
    "\n",
    "        chunk_size = config.CHUNK_SIZE\n",
    "        total_chunks = (len(selected_sessions) + chunk_size - 1) // chunk_size\n",
    "\n",
    "        all_validation_data = []\n",
    "        all_ground_truth = []\n",
    "\n",
    "        for chunk_idx in range(total_chunks):\n",
    "            start_idx = chunk_idx * chunk_size\n",
    "            end_idx = min(start_idx + chunk_size, len(selected_sessions))\n",
    "            chunk_sessions = selected_sessions[start_idx:end_idx]\n",
    "\n",
    "            if chunk_idx % 10 == 0:\n",
    "                progress = (chunk_idx / total_chunks) * 100\n",
    "                log(f\"    Processing chunk {chunk_idx + 1}/{total_chunks} ({progress:.1f}%)\")\n",
    "\n",
    "            # Get session data for this chunk\n",
    "            chunk_data = (\n",
    "                train_features_lazy\n",
    "                .filter(pl.col(\"session\").is_in(chunk_sessions))\n",
    "                .collect()\n",
    "            )\n",
    "\n",
    "            # Process each session in the chunk\n",
    "            for session_id in chunk_sessions:\n",
    "                session_data = chunk_data.filter(pl.col(\"session\") == session_id)\n",
    "\n",
    "                if len(session_data) == 0:\n",
    "                    continue\n",
    "\n",
    "                # Split session into train/test parts\n",
    "                session_events = session_data.sort(\"ts\")\n",
    "                total_events = len(session_events)\n",
    "\n",
    "                if total_events < 3:\n",
    "                    continue\n",
    "\n",
    "                # Use 70% for history, 30% for prediction\n",
    "                split_idx = max(1, int(total_events * 0.7))\n",
    "                train_part = session_events[:split_idx]\n",
    "                test_part = session_events[split_idx:]\n",
    "\n",
    "                # Generate candidates based on train part\n",
    "                candidates = generate_candidates_func(train_part, session_id)\n",
    "\n",
    "                # Create ground truth from test part\n",
    "                test_interactions = {}\n",
    "                for row in test_part.iter_rows(named=True):\n",
    "                    event_type = row['type']\n",
    "                    aid = row['aid']\n",
    "                    if event_type not in test_interactions:\n",
    "                        test_interactions[event_type] = set()\n",
    "                    test_interactions[event_type].add(aid)\n",
    "\n",
    "                # Generate validation samples\n",
    "                for event_type in [\"clicks\", \"carts\", \"orders\"]:\n",
    "                    if event_type in candidates and len(candidates[event_type]) > 0:\n",
    "                        # Create ground truth entry\n",
    "                        true_items = test_interactions.get(event_type, set())\n",
    "                        if len(true_items) > 0:\n",
    "                            all_ground_truth.append({\n",
    "                                \"session\": session_id,\n",
    "                                \"type\": event_type,\n",
    "                                \"ground_truth\": list(true_items)\n",
    "                            })\n",
    "\n",
    "                        # Create validation samples\n",
    "                        for candidate_aid in candidates[event_type]:\n",
    "                            label = 1 if candidate_aid in true_items else 0\n",
    "\n",
    "                            all_validation_data.append({\n",
    "                                \"session\": session_id,\n",
    "                                \"aid\": candidate_aid,\n",
    "                                \"type\": event_type,\n",
    "                                \"label\": label\n",
    "                            })\n",
    "\n",
    "            # Memory cleanup\n",
    "            if chunk_idx % 5 == 0:\n",
    "                check_memory_usage(\"Chunk processing\")\n",
    "\n",
    "        # Create final DataFrames\n",
    "        log(\"  Creating final DataFrames...\")\n",
    "\n",
    "        if len(all_validation_data) == 0:\n",
    "            raise ValueError(\"No validation data generated\")\n",
    "\n",
    "        val_data = pl.DataFrame(all_validation_data)\n",
    "        val_ground_truth = pl.DataFrame(all_ground_truth) if all_ground_truth else pl.DataFrame()\n",
    "\n",
    "        # Calculate statistics\n",
    "        total_samples = len(val_data)\n",
    "        positive_samples = val_data.filter(pl.col(\"label\") == 1).height\n",
    "        positive_rate = (positive_samples / total_samples) * 100 if total_samples > 0 else 0\n",
    "        unique_sessions = val_data['session'].n_unique()\n",
    "        unique_items = val_data['aid'].n_unique()\n",
    "\n",
    "        log(f\"  Validation data generated:\")\n",
    "        log(f\"    Total samples: {total_samples:,}\")\n",
    "        log(f\"    Positive samples: {positive_samples:,} ({positive_rate:.2f}%)\")\n",
    "        log(f\"    Unique sessions: {unique_sessions:,}\")\n",
    "        log(f\"    Unique items: {unique_items:,}\")\n",
    "        log(f\"    Ground truth entries: {len(val_ground_truth):,}\")\n",
    "\n",
    "        # Validate data quality\n",
    "        if positive_rate < config.MIN_POSITIVE_RATE * 100:\n",
    "            log(f\"  WARNING: Low positive rate {positive_rate:.2f}%, target was {config.MIN_POSITIVE_RATE * 100:.2f}%\")\n",
    "\n",
    "        if unique_items < config.MIN_ITEM_DIVERSITY:\n",
    "            log(f\"  WARNING: Low item diversity {unique_items}, target was {config.MIN_ITEM_DIVERSITY}\")\n",
    "\n",
    "        # Create split information\n",
    "        split_info = {\n",
    "            \"creation_timestamp\": datetime.now().isoformat(),\n",
    "            \"validation_days\": config.VALIDATION_DAYS,\n",
    "            \"val_cutoff_timestamp\": validation_cutoff,\n",
    "            \"total_timespan_days\": timespan_days,\n",
    "            \"train\": {\n",
    "                \"sessions\": validation_results.get('train_sessions', 0),\n",
    "                \"events\": validation_results.get('train_events', 0),\n",
    "                \"cutoff_ts\": validation_cutoff\n",
    "            },\n",
    "            \"val\": {\n",
    "                \"sessions\": unique_sessions,\n",
    "                \"samples\": total_samples,\n",
    "                \"positive_samples\": positive_samples,\n",
    "                \"positive_rate\": positive_rate,\n",
    "                \"unique_items\": unique_items\n",
    "            }\n",
    "        }\n",
    "\n",
    "        log(\"Enhanced validation data generation completed!\")\n",
    "        return val_data, val_ground_truth, split_info\n",
    "\n",
    "    except Exception as e:\n",
    "        log(f\"Error generating validation data: {e}\")\n",
    "        raise e\n",
    "\n",
    "# Generate validation data\n",
    "val_data, val_ground_truth, split_info = generate_enhanced_validation_data(\n",
    "    train_features_lazy, validation_results, generate_validation_candidates\n",
    ")\n",
    "\n",
    "check_memory_usage(\"Validation data generation\", force_cleanup=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3igkDafRY6fG"
   },
   "source": [
    "## ENHANCED DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vO3ZAYZmY8Ce",
    "outputId": "71f867ec-f9e2-465f-db58-73aae0498381"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-08 02:34:30] [MEM: 11.2GB/22.0%/OK] Analyzing enhanced training data...\n",
      "[2025-08-08 02:34:31] [MEM: 11.2GB/22.1%/OK]   Enhanced Data Quality Assessment:\n",
      "[2025-08-08 02:34:31] [MEM: 11.2GB/22.1%/OK]     Total samples: 6,617,259\n",
      "[2025-08-08 02:34:31] [MEM: 11.2GB/22.1%/OK]     Positive samples: 55,688 (0.84%)\n",
      "[2025-08-08 02:34:31] [MEM: 11.2GB/22.1%/OK]     Unique sessions: 25,000\n",
      "[2025-08-08 02:34:31] [MEM: 11.2GB/22.1%/OK]     Unique items: 543,691\n",
      "[2025-08-08 02:34:31] [MEM: 11.3GB/22.2%/OK]     clicks: 2,313,996 samples, 49,187 positive (2.13%), 25,000 sessions\n",
      "[2025-08-08 02:34:31] [MEM: 11.3GB/22.2%/OK]     carts: 2,153,154 samples, 4,646 positive (0.22%), 25,000 sessions\n",
      "[2025-08-08 02:34:31] [MEM: 11.3GB/22.2%/OK]     orders: 2,150,109 samples, 1,855 positive (0.09%), 25,000 sessions\n",
      "[2025-08-08 02:34:31] [MEM: 10.2GB/20.0%/OK]   Session-Level Analysis:\n",
      "[2025-08-08 02:34:31] [MEM: 10.2GB/20.0%/OK]     Avg positive per session: 2.2\n",
      "[2025-08-08 02:34:31] [MEM: 10.2GB/20.0%/OK]     Avg total per session: 264.7\n",
      "[2025-08-08 02:34:31] [MEM: 10.3GB/20.2%/OK]   Top 5 most frequent items:\n",
      "[2025-08-08 02:34:31] [MEM: 10.3GB/20.2%/OK]     1. Item 103562: 10006 appearances, 4 positive\n",
      "[2025-08-08 02:34:31] [MEM: 10.3GB/20.2%/OK]     2. Item 619779: 8960 appearances, 2 positive\n",
      "[2025-08-08 02:34:31] [MEM: 10.3GB/20.2%/OK]     3. Item 1574011: 8632 appearances, 5 positive\n",
      "[2025-08-08 02:34:31] [MEM: 10.3GB/20.2%/OK]     4. Item 448043: 8153 appearances, 0 positive\n",
      "[2025-08-08 02:34:31] [MEM: 10.3GB/20.2%/OK]     5. Item 361276: 7678 appearances, 0 positive\n",
      "[2025-08-08 02:34:31] [MEM: 10.3GB/20.2%/OK]   Quality Assessment:\n",
      "[2025-08-08 02:34:31] [MEM: 10.3GB/20.2%/OK]     ✓ sufficient_samples: PASS\n",
      "[2025-08-08 02:34:31] [MEM: 10.3GB/20.2%/OK]     ✓ adequate_positive_rate: PASS\n",
      "[2025-08-08 02:34:31] [MEM: 10.3GB/20.2%/OK]     ✓ item_diversity: PASS\n",
      "[2025-08-08 02:34:31] [MEM: 10.3GB/20.2%/OK]     ✓ session_coverage: PASS\n",
      "[2025-08-08 02:34:31] [MEM: 10.3GB/20.2%/OK]     ✓ balanced_types: PASS\n",
      "[2025-08-08 02:34:31] [MEM: 10.3GB/20.2%/OK]     Overall quality: EXCELLENT\n",
      "[2025-08-08 02:34:31] [MEM: 10.3GB/20.2%/OK] Enhanced data analysis completed!\n"
     ]
    }
   ],
   "source": [
    "def analyze_enhanced_training_data(val_data: pl.DataFrame,\n",
    "                                 split_info: Dict,\n",
    "                                 validation_results: Dict) -> Dict:\n",
    "    \"\"\"\n",
    "    Enhanced analysis of training data quality\n",
    "    \"\"\"\n",
    "    log(\"Analyzing enhanced training data...\")\n",
    "\n",
    "    try:\n",
    "        # Basic statistics\n",
    "        total_samples = len(val_data)\n",
    "        positive_samples = val_data.filter(pl.col(\"label\") == 1).height\n",
    "        positive_rate = (positive_samples / total_samples) * 100 if total_samples > 0 else 0\n",
    "        unique_sessions = val_data['session'].n_unique()\n",
    "        unique_items = val_data['aid'].n_unique()\n",
    "\n",
    "        log(f\"  Enhanced Data Quality Assessment:\")\n",
    "        log(f\"    Total samples: {total_samples:,}\")\n",
    "        log(f\"    Positive samples: {positive_samples:,} ({positive_rate:.2f}%)\")\n",
    "        log(f\"    Unique sessions: {unique_sessions:,}\")\n",
    "        log(f\"    Unique items: {unique_items:,}\")\n",
    "\n",
    "        # Per-type analysis\n",
    "        type_analysis = {}\n",
    "        for event_type in [\"clicks\", \"carts\", \"orders\"]:\n",
    "            type_data = val_data.filter(pl.col(\"type\") == event_type)\n",
    "            if len(type_data) > 0:\n",
    "                type_positive = type_data.filter(pl.col(\"label\") == 1).height\n",
    "                type_total = len(type_data)\n",
    "                type_rate = (type_positive / type_total) * 100 if type_total > 0 else 0\n",
    "                type_sessions = type_data['session'].n_unique()\n",
    "\n",
    "                type_analysis[event_type] = {\n",
    "                    \"total_samples\": type_total,\n",
    "                    \"positive_samples\": type_positive,\n",
    "                    \"positive_rate\": type_rate,\n",
    "                    \"sessions\": type_sessions\n",
    "                }\n",
    "\n",
    "                log(f\"    {event_type}: {type_total:,} samples, {type_positive:,} positive ({type_rate:.2f}%), {type_sessions:,} sessions\")\n",
    "\n",
    "        # Session-level analysis\n",
    "        session_stats = (\n",
    "            val_data\n",
    "            .group_by(\"session\")\n",
    "            .agg([\n",
    "                pl.col(\"label\").sum().alias(\"positive_count\"),\n",
    "                pl.col(\"label\").count().alias(\"total_count\")\n",
    "            ])\n",
    "        )\n",
    "\n",
    "        avg_positive_per_session = session_stats['positive_count'].mean()\n",
    "        avg_total_per_session = session_stats['total_count'].mean()\n",
    "\n",
    "        log(f\"  Session-Level Analysis:\")\n",
    "        log(f\"    Avg positive per session: {avg_positive_per_session:.1f}\")\n",
    "        log(f\"    Avg total per session: {avg_total_per_session:.1f}\")\n",
    "\n",
    "        # Item popularity analysis\n",
    "        item_stats = (\n",
    "            val_data\n",
    "            .group_by(\"aid\")\n",
    "            .agg([\n",
    "                pl.col(\"label\").sum().alias(\"positive_count\"),\n",
    "                pl.col(\"label\").count().alias(\"total_count\")\n",
    "            ])\n",
    "            .sort(\"total_count\", descending=True)\n",
    "        )\n",
    "\n",
    "        top_items = item_stats.head(5)\n",
    "        log(f\"  Top 5 most frequent items:\")\n",
    "        for i, row in enumerate(top_items.iter_rows(named=True)):\n",
    "            log(f\"    {i+1}. Item {row['aid']}: {row['total_count']} appearances, {row['positive_count']} positive\")\n",
    "\n",
    "        # Quality checks\n",
    "        quality_checks = {\n",
    "            \"sufficient_samples\": total_samples >= 100000,\n",
    "            \"adequate_positive_rate\": positive_rate >= 0.1,\n",
    "            \"item_diversity\": unique_items >= 50,\n",
    "            \"session_coverage\": unique_sessions >= 1000,\n",
    "            \"balanced_types\": len(type_analysis) == 3\n",
    "        }\n",
    "\n",
    "        overall_quality = \"EXCELLENT\" if all(quality_checks.values()) else \"GOOD\" if sum(quality_checks.values()) >= 3 else \"NEEDS_IMPROVEMENT\"\n",
    "\n",
    "        log(f\"  Quality Assessment:\")\n",
    "        for check, passed in quality_checks.items():\n",
    "            status = \"✓\" if passed else \"✗\"\n",
    "            log(f\"    {status} {check}: {'PASS' if passed else 'FAIL'}\")\n",
    "        log(f\"    Overall quality: {overall_quality}\")\n",
    "\n",
    "        # Create comprehensive statistics\n",
    "        statistics = {\n",
    "            \"analysis_timestamp\": datetime.now().isoformat(),\n",
    "            \"data_quality\": overall_quality,\n",
    "            \"validation_data\": {\n",
    "                \"total_samples\": total_samples,\n",
    "                \"positive_samples\": positive_samples,\n",
    "                \"positive_rate\": positive_rate,\n",
    "                \"unique_sessions\": unique_sessions,\n",
    "                \"unique_items\": unique_items\n",
    "            },\n",
    "            \"event_type_analysis\": type_analysis,\n",
    "            \"session_statistics\": {\n",
    "                \"avg_positive_per_session\": avg_positive_per_session,\n",
    "                \"avg_total_per_session\": avg_total_per_session\n",
    "            },\n",
    "            \"quality_checks\": quality_checks,\n",
    "            \"split_info\": split_info,\n",
    "            \"input_validation\": validation_results\n",
    "        }\n",
    "\n",
    "        log(\"Enhanced data analysis completed!\")\n",
    "        return statistics\n",
    "\n",
    "    except Exception as e:\n",
    "        log(f\"Error in data analysis: {e}\")\n",
    "        return {\"error\": str(e), \"timestamp\": datetime.now().isoformat()}\n",
    "\n",
    "# Analyze the generated data\n",
    "training_data_statistics = analyze_enhanced_training_data(val_data, split_info, validation_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4GmjiRoaY-5t"
   },
   "source": [
    "## ENHANCED OUTPUT SAVING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k6WV_h-YdG7y",
    "outputId": "dc70f221-f1f9-4232-80ea-f3f48ccff532"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-08 02:34:31] [MEM: 10.2GB/20.0%/OK] Saving enhanced outputs...\n",
      "[2025-08-08 02:34:32] [MEM: 10.2GB/20.0%/OK]   ✓ val_data.parquet saved (24.4 MB)\n",
      "[2025-08-08 02:34:32] [MEM: 10.2GB/20.0%/OK]   ✓ train_val_splits.pkl saved\n",
      "[2025-08-08 02:34:32] [MEM: 10.2GB/20.0%/OK]   ✓ validation_ground_truth.parquet saved (1.9 MB)\n",
      "[2025-08-08 02:34:32] [MEM: 10.2GB/20.0%/OK]   ✓ training_data_statistics.pkl saved\n",
      "[2025-08-08 02:34:32] [MEM: 10.2GB/20.0%/OK]   ✓ part_2b2_enhanced_summary.pkl saved\n",
      "[2025-08-08 02:34:32] [MEM: 10.2GB/20.0%/OK] All enhanced outputs saved successfully!\n"
     ]
    }
   ],
   "source": [
    "def save_enhanced_outputs(val_data: pl.DataFrame,\n",
    "                         val_ground_truth: pl.DataFrame,\n",
    "                         split_info: Dict,\n",
    "                         statistics: Dict) -> Dict:\n",
    "    \"\"\"\n",
    "    Save all outputs with enhanced error handling\n",
    "    \"\"\"\n",
    "    log(\"Saving enhanced outputs...\")\n",
    "\n",
    "    try:\n",
    "        # Ensure output directory exists\n",
    "        os.makedirs(config.OUTPUT_PATH, exist_ok=True)\n",
    "\n",
    "        output_paths = {}\n",
    "\n",
    "        # 1. Save validation data (main output)\n",
    "        val_data_path = f\"{config.OUTPUT_PATH}/val_data.parquet\"\n",
    "        val_data.write_parquet(val_data_path, compression=\"snappy\")\n",
    "        file_size = os.path.getsize(val_data_path) / (1024*1024)\n",
    "        log(f\"  ✓ val_data.parquet saved ({file_size:.1f} MB)\")\n",
    "        output_paths[\"val_data_path\"] = val_data_path\n",
    "\n",
    "        # 2. Save train/validation splits\n",
    "        splits_path = f\"{config.OUTPUT_PATH}/train_val_splits.pkl\"\n",
    "        with open(splits_path, \"wb\") as f:\n",
    "            pickle.dump(split_info, f)\n",
    "        log(f\"  ✓ train_val_splits.pkl saved\")\n",
    "        output_paths[\"splits_path\"] = splits_path\n",
    "\n",
    "        # 3. Save validation ground truth\n",
    "        if len(val_ground_truth) > 0:\n",
    "            gt_path = f\"{config.OUTPUT_PATH}/validation_ground_truth.parquet\"\n",
    "            val_ground_truth.write_parquet(gt_path, compression=\"snappy\")\n",
    "            file_size = os.path.getsize(gt_path) / (1024*1024)\n",
    "            log(f\"  ✓ validation_ground_truth.parquet saved ({file_size:.1f} MB)\")\n",
    "            output_paths[\"ground_truth_path\"] = gt_path\n",
    "\n",
    "        # 4. Save training data statistics (use pickle instead of JSON to avoid serialization issues)\n",
    "        stats_path = f\"{config.OUTPUT_PATH}/training_data_statistics.pkl\"\n",
    "        with open(stats_path, \"wb\") as f:\n",
    "            pickle.dump(statistics, f)\n",
    "        log(f\"  ✓ training_data_statistics.pkl saved\")\n",
    "        output_paths[\"statistics_path\"] = stats_path\n",
    "\n",
    "        # 5. Save summary report\n",
    "        summary = {\n",
    "            \"notebook\": \"Part 2B2: Enhanced Training Data Preparation\",\n",
    "            \"completion_timestamp\": datetime.now().isoformat(),\n",
    "            \"version\": \"FIXED - Enhanced positive sample generation\",\n",
    "            \"data_quality\": statistics.get(\"data_quality\", \"UNKNOWN\"),\n",
    "            \"key_improvements\": [\n",
    "                f\"Increased validation sessions to {config.MAX_VALIDATION_SESSIONS:,}\",\n",
    "                f\"Increased candidates per type to {config.VALIDATION_CANDIDATES_PER_TYPE}\",\n",
    "                \"Enhanced candidate generation strategies\",\n",
    "                \"Fixed variable scoping and error handling\",\n",
    "                \"Improved positive sample generation\"\n",
    "            ],\n",
    "            \"outputs_generated\": {\n",
    "                \"val_data.parquet\": f\"{len(val_data):,} samples with labels\",\n",
    "                \"train_val_splits.pkl\": \"Enhanced train/validation split info\",\n",
    "                \"validation_ground_truth.parquet\": f\"{len(val_ground_truth):,} ground truth entries\",\n",
    "                \"training_data_statistics.pkl\": \"Comprehensive data analysis\"\n",
    "            },\n",
    "            \"quality_metrics\": statistics.get(\"validation_data\", {}),\n",
    "            \"next_step\": \"Run Part 2B3: Feature Engineering\"\n",
    "        }\n",
    "\n",
    "        summary_path = f\"{config.OUTPUT_PATH}/part_2b2_enhanced_summary.pkl\"\n",
    "        with open(summary_path, \"wb\") as f:\n",
    "            pickle.dump(summary, f)\n",
    "        log(f\"  ✓ part_2b2_enhanced_summary.pkl saved\")\n",
    "        output_paths[\"summary_path\"] = summary_path\n",
    "\n",
    "        log(\"All enhanced outputs saved successfully!\")\n",
    "        return output_paths\n",
    "\n",
    "    except Exception as e:\n",
    "        log(f\"Error saving outputs: {e}\")\n",
    "        raise e\n",
    "\n",
    "# Save all outputs\n",
    "output_paths = save_enhanced_outputs(val_data, val_ground_truth, split_info, training_data_statistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Xls1nGrdJ0Z"
   },
   "source": [
    "## ENHANCED FINAL SUMMARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fnrWRi1KdL1K",
    "outputId": "7caf770a-c937-493d-cd19-90c5c08595d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-08 02:34:32] [MEM: 10.2GB/20.0%/OK] \n",
      "================================================================================\n",
      "[2025-08-08 02:34:32] [MEM: 10.2GB/20.0%/OK] PART 2B2 COMPLETED: ENHANCED TRAINING DATA PREPARATION\n",
      "[2025-08-08 02:34:32] [MEM: 10.2GB/20.0%/OK] ================================================================================\n",
      "[2025-08-08 02:34:32] [MEM: 10.2GB/20.0%/OK] \n",
      "KEY RESULTS (ENHANCED):\n",
      "[2025-08-08 02:34:32] [MEM: 10.2GB/20.0%/OK]   Validation samples: 6,617,259\n",
      "[2025-08-08 02:34:32] [MEM: 10.2GB/20.0%/OK]   Positive samples: 55,688 (0.84%)\n",
      "[2025-08-08 02:34:32] [MEM: 10.2GB/20.0%/OK]   Unique sessions: 25,000\n",
      "[2025-08-08 02:34:32] [MEM: 10.2GB/20.0%/OK]   Unique items: 543,691\n",
      "[2025-08-08 02:34:32] [MEM: 10.2GB/20.0%/OK]   Data quality: EXCELLENT\n",
      "[2025-08-08 02:34:32] [MEM: 10.2GB/20.0%/OK] \n",
      "PER-TYPE ANALYSIS:\n",
      "[2025-08-08 02:34:32] [MEM: 10.2GB/20.0%/OK]   clicks: 2,313,996 samples, 49,187 positive (2.13%)\n",
      "[2025-08-08 02:34:32] [MEM: 10.2GB/20.0%/OK]   carts: 2,153,154 samples, 4,646 positive (0.22%)\n",
      "[2025-08-08 02:34:32] [MEM: 10.2GB/20.0%/OK]   orders: 2,150,109 samples, 1,855 positive (0.09%)\n",
      "[2025-08-08 02:34:32] [MEM: 10.2GB/20.0%/OK] \n",
      "OUTPUT FILES GENERATED:\n",
      "[2025-08-08 02:34:32] [MEM: 10.2GB/20.0%/OK]   val_data.parquet (24.4 MB)\n",
      "[2025-08-08 02:34:32] [MEM: 10.2GB/20.0%/OK]   train_val_splits.pkl\n",
      "[2025-08-08 02:34:32] [MEM: 10.2GB/20.0%/OK]   validation_ground_truth.parquet (1.9 MB)\n",
      "[2025-08-08 02:34:32] [MEM: 10.2GB/20.0%/OK]   training_data_statistics.pkl\n",
      "[2025-08-08 02:34:32] [MEM: 10.2GB/20.0%/OK]   part_2b2_enhanced_summary.pkl\n",
      "[2025-08-08 02:34:32] [MEM: 10.2GB/20.0%/OK]   All files saved to: /content/drive/MyDrive/Colab Notebooks/CML/Assignment 1/content/otto-output\n",
      "[2025-08-08 02:34:32] [MEM: 10.2GB/20.0%/OK] \n",
      "QUALITY ASSESSMENT:\n",
      "[2025-08-08 02:34:32] [MEM: 10.2GB/20.0%/OK]   Sufficient Samples: yes\n",
      "[2025-08-08 02:34:32] [MEM: 10.2GB/20.0%/OK]   Adequate Positive Rate: yes\n",
      "[2025-08-08 02:34:32] [MEM: 10.2GB/20.0%/OK]   Item Diversity: yes\n",
      "[2025-08-08 02:34:32] [MEM: 10.2GB/20.0%/OK]   Session Coverage: yes\n",
      "[2025-08-08 02:34:32] [MEM: 10.2GB/20.0%/OK]   Balanced Types: yes\n",
      "[2025-08-08 02:34:32] [MEM: 10.2GB/20.0%/OK] \n",
      "Overall Quality: EXCELLENT\n",
      "[2025-08-08 02:34:32] [MEM: 10.2GB/20.0%/OK] \n",
      "PERFORMANCE SUMMARY:\n",
      "[2025-08-08 02:34:32] [MEM: 10.2GB/20.0%/OK]   Final memory usage: 10.2 GB\n",
      "[2025-08-08 02:34:32] [MEM: 10.2GB/20.0%/OK]   Max validation sessions: 25,000\n",
      "[2025-08-08 02:34:32] [MEM: 10.2GB/20.0%/OK]   Candidates per type: 100\n",
      "[2025-08-08 02:34:32] [MEM: 10.2GB/20.0%/OK]   Enhanced features: Enabled\n",
      "[2025-08-08 02:34:32] [MEM: 10.2GB/20.0%/OK] \n",
      "Performing final cleanup...\n",
      "[2025-08-08 02:34:42] [MEM: 10.2GB/20.0%/OK] Final memory usage after cleanup: 10.2 GB\n",
      "[2025-08-08 02:34:42] [MEM: 10.2GB/20.0%/OK] \n",
      "Part 2B2 Enhanced finished successfully!\n",
      "[2025-08-08 02:34:42] [MEM: 10.2GB/20.0%/OK] ================================================================================\n"
     ]
    }
   ],
   "source": [
    "log(\"\\n\" + \"=\"*80)\n",
    "log(\"PART 2B2 COMPLETED: ENHANCED TRAINING DATA PREPARATION\")\n",
    "log(\"=\"*80)\n",
    "\n",
    "# Display key results\n",
    "val_data_info = training_data_statistics.get('validation_data', {})\n",
    "log(f\"\\nKEY RESULTS (ENHANCED):\")\n",
    "log(f\"  Validation samples: {val_data_info.get('total_samples', 0):,}\")\n",
    "log(f\"  Positive samples: {val_data_info.get('positive_samples', 0):,} ({val_data_info.get('positive_rate', 0):.2f}%)\")\n",
    "log(f\"  Unique sessions: {val_data_info.get('unique_sessions', 0):,}\")\n",
    "log(f\"  Unique items: {val_data_info.get('unique_items', 0):,}\")\n",
    "log(f\"  Data quality: {training_data_statistics.get('data_quality', 'UNKNOWN')}\")\n",
    "\n",
    "# Per-type breakdown\n",
    "log(f\"\\nPER-TYPE ANALYSIS:\")\n",
    "type_analysis = training_data_statistics.get('event_type_analysis', {})\n",
    "for event_type in [\"clicks\", \"carts\", \"orders\"]:\n",
    "    if event_type in type_analysis:\n",
    "        stats = type_analysis[event_type]\n",
    "        log(f\"  {event_type}: {stats['total_samples']:,} samples, {stats['positive_samples']:,} positive ({stats['positive_rate']:.2f}%)\")\n",
    "\n",
    "# Output files\n",
    "log(f\"\\nOUTPUT FILES GENERATED:\")\n",
    "log(f\"  val_data.parquet ({os.path.getsize(output_paths['val_data_path'])/(1024*1024):.1f} MB)\")\n",
    "log(f\"  train_val_splits.pkl\")\n",
    "if \"ground_truth_path\" in output_paths:\n",
    "    log(f\"  validation_ground_truth.parquet ({os.path.getsize(output_paths['ground_truth_path'])/(1024*1024):.1f} MB)\")\n",
    "log(f\"  training_data_statistics.pkl\")\n",
    "log(f\"  part_2b2_enhanced_summary.pkl\")\n",
    "log(f\"  All files saved to: {config.OUTPUT_PATH}\")\n",
    "\n",
    "# Quality assessment\n",
    "quality_checks = training_data_statistics.get('quality_checks', {})\n",
    "log(f\"\\nQUALITY ASSESSMENT:\")\n",
    "for check, passed in quality_checks.items():\n",
    "    status = \"yes\" if passed else \"no\"\n",
    "    log(f\"  {check.replace('_', ' ').title()}: {status}\")\n",
    "\n",
    "overall_quality = training_data_statistics.get('data_quality', 'UNKNOWN')\n",
    "log(f\"\\nOverall Quality: {overall_quality}\")\n",
    "\n",
    "# Performance summary\n",
    "final_memory = get_memory_usage()\n",
    "log(f\"\\nPERFORMANCE SUMMARY:\")\n",
    "log(f\"  Final memory usage: {final_memory:.1f} GB\")\n",
    "log(f\"  Max validation sessions: {config.MAX_VALIDATION_SESSIONS:,}\")\n",
    "log(f\"  Candidates per type: {config.VALIDATION_CANDIDATES_PER_TYPE}\")\n",
    "log(f\"  Enhanced features: Enabled\")\n",
    "\n",
    "# Final cleanup\n",
    "log(f\"\\nPerforming final cleanup...\")\n",
    "try:\n",
    "    del train_features_lazy, consolidated_covisitation_matrices\n",
    "    force_garbage_collection()\n",
    "    final_memory = get_memory_usage()\n",
    "    log(f\"Final memory usage after cleanup: {final_memory:.1f} GB\")\n",
    "except Exception as e:\n",
    "    log(f\"Cleanup warning: {e}\")\n",
    "\n",
    "log(f\"\\nPart 2B2 Enhanced finished successfully!\")\n",
    "log(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
