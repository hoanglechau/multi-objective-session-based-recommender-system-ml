{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mG5KNO7VPPYo"
   },
   "source": [
    "# Part 2B1 Test Candidate Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G4Kap4SxPH5M",
    "outputId": "797c730d-1d05-4f8d-a6f1-e8937b4389d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: polars==0.20.31 in /usr/local/lib/python3.11/dist-packages (0.20.31)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install polars==0.20.31 tqdm\n",
    "\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import time\n",
    "import psutil\n",
    "from typing import Dict, List, Tuple, Optional, Iterator\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p5lmAwCiPT2b",
    "outputId": "fce44995-2a3d-47a8-fabe-66d85dde7473"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8r3t92psPVqk"
   },
   "outputs": [],
   "source": [
    "# Configuration\n",
    "class Config:\n",
    "    DATA_PATH = '/content/drive/MyDrive/Colab Notebooks/CML/Assignment 1/content/otto-data'\n",
    "    OUTPUT_PATH = '/content/drive/MyDrive/Colab Notebooks/CML/Assignment 1/content/otto-output'\n",
    "\n",
    "    N_CANDIDATES = 100  # Candidates per session-type combination\n",
    "    CHUNK_SIZE = 2500   # Reduced chunk size for memory efficiency\n",
    "    MAX_MEMORY_GB = 45  # Maximum memory usage before cleanup\n",
    "\n",
    "    # Memory management settings\n",
    "    GC_FREQUENCY = 10   # Run garbage collection every N chunks\n",
    "    PROGRESS_UPDATE = 5 # Update progress every N chunks\n",
    "\n",
    "config = Config()\n",
    "\n",
    "def get_memory_usage():\n",
    "    \"\"\"Get current memory usage in GB\"\"\"\n",
    "    return psutil.Process().memory_info().rss / (1024**3)\n",
    "\n",
    "def memory_cleanup():\n",
    "    \"\"\"Force garbage collection and memory cleanup\"\"\"\n",
    "    gc.collect()\n",
    "    time.sleep(0.1)  # Brief pause to allow cleanup\n",
    "\n",
    "def monitor_memory(operation_name: str, force_cleanup: bool = False):\n",
    "    \"\"\"Monitor memory usage and cleanup if necessary\"\"\"\n",
    "    memory_gb = get_memory_usage()\n",
    "    if memory_gb > config.MAX_MEMORY_GB or force_cleanup:\n",
    "        print(f\"   Memory cleanup triggered at {memory_gb:.1f}GB during {operation_name}\")\n",
    "        memory_cleanup()\n",
    "        new_memory = get_memory_usage()\n",
    "        print(f\"   Memory after cleanup: {new_memory:.1f}GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wW9M416RPgi4"
   },
   "source": [
    "## LOGGING SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rmbkV_iZPeD0",
    "outputId": "b462facb-4846-46c7-ac8f-be4920eaf37b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 20:47:58] [0.2GB] ================================================================================\n",
      "[2025-08-07 20:47:58] [0.2GB] OTTO PART 2B1: TEST CANDIDATE GENERATION STARTED (MEMORY OPTIMIZED)\n",
      "[2025-08-07 20:47:58] [0.2GB] ================================================================================\n"
     ]
    }
   ],
   "source": [
    "def setup_logging():\n",
    "    \"\"\"Setup logging for this notebook\"\"\"\n",
    "    log_file = f\"{config.OUTPUT_PATH}/candidate_generation_log.txt\"\n",
    "\n",
    "    def log_message(message):\n",
    "        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        memory_gb = get_memory_usage()\n",
    "        log_entry = f\"[{timestamp}] [{memory_gb:.1f}GB] {message}\"\n",
    "        print(log_entry)\n",
    "\n",
    "        # Also write to file\n",
    "        with open(log_file, \"a\") as f:\n",
    "            f.write(log_entry + \"\\n\")\n",
    "\n",
    "    return log_message\n",
    "\n",
    "log = setup_logging()\n",
    "\n",
    "log(\"=\"*80)\n",
    "log(\"OTTO PART 2B1: TEST CANDIDATE GENERATION STARTED (MEMORY OPTIMIZED)\")\n",
    "log(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mhyWbWFRPjYW"
   },
   "source": [
    "## # INPUT VALIDATION AND DATA LOADING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SbbJnE4jPlZD",
    "outputId": "f12502b8-fe22-49ff-9510-b0b43b24fb5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 20:47:58] [0.2GB] Validating input files...\n",
      "[2025-08-07 20:47:58] [0.2GB] test_clean.parquet - 55.3 MB\n",
      "[2025-08-07 20:47:58] [0.2GB] item_stats.parquet - 0.0 MB\n",
      "[2025-08-07 20:47:58] [0.2GB] consolidated_covisitation_matrices.pkl - 1122.3 MB\n",
      "[2025-08-07 20:47:58] [0.2GB] All required input files found!\n",
      "[2025-08-07 20:47:58] [0.2GB] \n",
      "Loading input data...\n",
      "[2025-08-07 20:47:58] [0.2GB]    Loading test data...\n",
      "[2025-08-07 20:47:58] [0.4GB]    Test data: (6924640, 4) (132.1 MB)\n",
      "[2025-08-07 20:47:58] [0.4GB]    Loading item statistics...\n",
      "[2025-08-07 20:47:58] [0.4GB]    Item stats: (1000, 6) (0.0 MB)\n",
      "[2025-08-07 20:47:58] [0.4GB]    Loading co-visitation matrices...\n",
      "[2025-08-07 20:48:23] [9.9GB]    Co-visitation matrices from: consolidated_covisitation_matrices.pkl (1122.3 MB)\n",
      "[2025-08-07 20:48:23] [9.9GB]    Validating co-visitation matrices...\n",
      "[2025-08-07 20:48:23] [9.9GB]    Matrix data type: <class 'dict'>\n",
      "[2025-08-07 20:48:23] [9.9GB]    Matrix keys: ['matrices', 'metadata', 'summary']\n",
      "[2025-08-07 20:48:23] [9.9GB]    Checking matrix 'matrices' of type: <class 'dict'>\n",
      "[2025-08-07 20:48:23] [9.9GB]    GOOD matrices: 3 items, 2,389,818 pairs (dict)\n",
      "[2025-08-07 20:48:23] [9.9GB]    Checking matrix 'metadata' of type: <class 'dict'>\n",
      "[2025-08-07 20:48:23] [9.9GB]    GOOD metadata: 5 items, 9 pairs (dict)\n",
      "[2025-08-07 20:48:23] [9.9GB]    Checking matrix 'summary' of type: <class 'dict'>\n",
      "[2025-08-07 20:48:23] [9.9GB]    GOOD summary: 4 items, 4 pairs (dict)\n",
      "[2025-08-07 20:48:23] [9.9GB]    Total: 12 source items, 2,389,831 pairs\n",
      "   Memory cleanup triggered at 9.9GB during matrix validation\n",
      "   Memory after cleanup: 9.9GB\n",
      "[2025-08-07 20:48:27] [10.1GB] Input validation completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# INPUT VALIDATION AND DATA LOADING\n",
    "def validate_and_load_inputs():\n",
    "    \"\"\"\n",
    "    Validate that all required input files exist and load them efficiently\n",
    "\n",
    "    Returns:\n",
    "        tuple: (test_df, item_stats, consolidated_covisitation_matrices, validation_results)\n",
    "    \"\"\"\n",
    "    log(\"Validating input files...\")\n",
    "\n",
    "    # Required input files\n",
    "    required_files = {\n",
    "        \"test_clean.parquet\": \"Clean test data from Part 1\",\n",
    "        \"item_stats.parquet\": \"Item statistics from Part 1\",\n",
    "        \"consolidated_covisitation_matrices.pkl\": \"Co-visitation matrices from Part 2A\"\n",
    "    }\n",
    "\n",
    "    # Check if files exist\n",
    "    missing_files = []\n",
    "    for filename, description in required_files.items():\n",
    "        filepath = f\"{config.OUTPUT_PATH}/{filename}\"\n",
    "        if not os.path.exists(filepath):\n",
    "            missing_files.append(f\"{filename} - {description}\")\n",
    "        else:\n",
    "            file_size = os.path.getsize(filepath) / (1024*1024)  # MB\n",
    "            log(f\"{filename} - {file_size:.1f} MB\")\n",
    "\n",
    "    if missing_files:\n",
    "        log(\"MISSING REQUIRED INPUT FILES:\")\n",
    "        for missing in missing_files:\n",
    "            log(f\"   {missing}\")\n",
    "        log(\"\\nTO FIX THIS:\")\n",
    "        log(\"   1. Run Part 1 (Data Processing) to generate test_clean.parquet and item_stats.parquet\")\n",
    "        log(\"   2. Run Part 2A (Co-visitation Matrix Generation) to generate consolidated_covisitation_matrices.pkl\")\n",
    "        raise FileNotFoundError(\"Required input files are missing!\")\n",
    "\n",
    "    log(\"All required input files found!\")\n",
    "\n",
    "    # Load data efficiently\n",
    "    log(\"\\nLoading input data...\")\n",
    "\n",
    "    try:\n",
    "        # Load test data with memory optimization\n",
    "        log(\"   Loading test data...\")\n",
    "        test_df = pl.read_parquet(f\"{config.OUTPUT_PATH}/test_clean.parquet\")\n",
    "        log(f\"   Test data: {test_df.shape} ({test_df.estimated_size('mb'):.1f} MB)\")\n",
    "        monitor_memory(\"test data loading\")\n",
    "\n",
    "        # Load item statistics\n",
    "        log(\"   Loading item statistics...\")\n",
    "        item_stats = pl.read_parquet(f\"{config.OUTPUT_PATH}/item_stats.parquet\")\n",
    "        log(f\"   Item stats: {item_stats.shape} ({item_stats.estimated_size('mb'):.1f} MB)\")\n",
    "        monitor_memory(\"item stats loading\")\n",
    "\n",
    "        # Load co-visitation matrices with fallback options\n",
    "        log(\"   Loading co-visitation matrices...\")\n",
    "        covisit_files = [\n",
    "            \"consolidated_covisitation_matrices.pkl\",\n",
    "            \"consolidated_covisitation_matrices_partial.pkl\",\n",
    "            \"consolidated_covisitation_matrices_minimal.pkl\"\n",
    "        ]\n",
    "\n",
    "        consolidated_covisitation_matrices = None\n",
    "        matrix_source = None\n",
    "\n",
    "        for filename in covisit_files:\n",
    "            filepath = f\"{config.OUTPUT_PATH}/{filename}\"\n",
    "            if os.path.exists(filepath):\n",
    "                try:\n",
    "                    with open(filepath, \"rb\") as f:\n",
    "                        consolidated_covisitation_matrices = pickle.load(f)\n",
    "                    matrix_source = filename\n",
    "                    file_size = os.path.getsize(filepath) / (1024*1024)\n",
    "                    log(f\"   Co-visitation matrices from: {filename} ({file_size:.1f} MB)\")\n",
    "                    monitor_memory(\"covisitation matrices loading\")\n",
    "                    break\n",
    "                except Exception as e:\n",
    "                    log(f\"   Failed to load {filename}: {e}\")\n",
    "                    continue\n",
    "\n",
    "        if consolidated_covisitation_matrices is None:\n",
    "            raise FileNotFoundError(\"No co-visitation matrices could be loaded!\")\n",
    "\n",
    "        # Validate matrices with proper type checking\n",
    "        log(\"   Validating co-visitation matrices...\")\n",
    "        matrix_validation = {}\n",
    "        total_source_items = 0\n",
    "        total_pairs = 0\n",
    "\n",
    "        # First, check what type of data structure we have\n",
    "        log(f\"   Matrix data type: {type(consolidated_covisitation_matrices)}\")\n",
    "        log(f\"   Matrix keys: {list(consolidated_covisitation_matrices.keys()) if isinstance(consolidated_covisitation_matrices, dict) else 'Not a dictionary'}\")\n",
    "\n",
    "        for name, matrix in consolidated_covisitation_matrices.items():\n",
    "            log(f\"   Checking matrix '{name}' of type: {type(matrix)}\")\n",
    "\n",
    "            # Handle different matrix types safely\n",
    "            try:\n",
    "                if matrix is None:\n",
    "                    source_items = 0\n",
    "                    pairs = 0\n",
    "                    status = \"empty\"\n",
    "                elif isinstance(matrix, dict):\n",
    "                    source_items = len(matrix)\n",
    "                    pairs = 0\n",
    "                    # Calculate pairs safely\n",
    "                    for item_id, candidates in matrix.items():\n",
    "                        try:\n",
    "                            if isinstance(candidates, (list, tuple)):\n",
    "                                pairs += len(candidates)\n",
    "                            elif isinstance(candidates, dict):\n",
    "                                pairs += len(candidates)\n",
    "                            elif isinstance(candidates, int):\n",
    "                                pairs += 1  # Single candidate\n",
    "                            else:\n",
    "                                pairs += 1  # Unknown format, count as 1\n",
    "                        except Exception as e:\n",
    "                            log(f\"     Warning: Error counting pairs for item {item_id}: {e}\")\n",
    "                            pairs += 1  # Fallback count\n",
    "                    status = \"good\" if source_items > 0 else \"empty\"\n",
    "                elif isinstance(matrix, (list, tuple)):\n",
    "                    source_items = len(matrix)\n",
    "                    pairs = source_items  # Assume each item is a pair\n",
    "                    status = \"list_format\" if source_items > 0 else \"empty\"\n",
    "                elif isinstance(matrix, int):\n",
    "                    # Matrix is just a count or single value\n",
    "                    source_items = matrix if matrix > 0 else 0\n",
    "                    pairs = matrix if matrix > 0 else 0\n",
    "                    status = \"count_format\" if source_items > 0 else \"empty\"\n",
    "                else:\n",
    "                    # Unknown format\n",
    "                    log(f\"     Warning: Unknown matrix format for '{name}': {type(matrix)}\")\n",
    "                    source_items = 1 if matrix else 0\n",
    "                    pairs = 1 if matrix else 0\n",
    "                    status = \"unknown_format\" if matrix else \"empty\"\n",
    "\n",
    "                matrix_validation[name] = {\n",
    "                    \"source_items\": source_items,\n",
    "                    \"total_pairs\": pairs,\n",
    "                    \"status\": status,\n",
    "                    \"data_type\": str(type(matrix).__name__)\n",
    "                }\n",
    "\n",
    "                total_source_items += source_items\n",
    "                total_pairs += pairs\n",
    "\n",
    "                log(f\"   {status.upper()} {name}: {source_items:,} items, {pairs:,} pairs ({matrix_validation[name]['data_type']})\")\n",
    "\n",
    "            except Exception as e:\n",
    "                log(f\"   ERROR validating matrix '{name}': {e}\")\n",
    "                matrix_validation[name] = {\n",
    "                    \"source_items\": 0,\n",
    "                    \"total_pairs\": 0,\n",
    "                    \"status\": \"error\",\n",
    "                    \"data_type\": str(type(matrix).__name__),\n",
    "                    \"error\": str(e)\n",
    "                }\n",
    "\n",
    "        log(f\"   Total: {total_source_items:,} source items, {total_pairs:,} pairs\")\n",
    "        monitor_memory(\"matrix validation\", force_cleanup=True)\n",
    "\n",
    "        # Save validation results\n",
    "        validation_results = {\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"matrix_source\": matrix_source,\n",
    "            \"test_sessions\": test_df.select(\"session\").n_unique(),\n",
    "            \"test_events\": len(test_df),\n",
    "            \"matrix_validation\": matrix_validation,\n",
    "            \"total_source_items\": total_source_items,\n",
    "            \"total_pairs\": total_pairs\n",
    "        }\n",
    "\n",
    "        log(\"Input validation completed successfully!\")\n",
    "        return test_df, item_stats, consolidated_covisitation_matrices, validation_results\n",
    "\n",
    "    except Exception as e:\n",
    "        log(f\"Error loading input data: {e}\")\n",
    "        raise e\n",
    "\n",
    "# Load and validate inputs\n",
    "test_df, item_stats, consolidated_covisitation_matrices, validation_results = validate_and_load_inputs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "95lC22-4PpX1"
   },
   "source": [
    "## # CANDIDATE GENERATION ENGINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nrVXMmFoPrVK",
    "outputId": "0c54e4da-afb6-4c4c-8760-a30935bcff75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 20:48:27] [10.1GB] Setting up candidate generation engine...\n",
      "[2025-08-07 20:48:27] [10.1GB]    Popular items prepared: 50 clicks, 50 carts, 50 orders\n",
      "[2025-08-07 20:48:27] [10.1GB]    Matrix 'matrices': 3 items (usable)\n",
      "[2025-08-07 20:48:27] [10.1GB]    Matrix 'metadata': 5 items (usable)\n",
      "[2025-08-07 20:48:27] [10.1GB]    Matrix 'summary': 4 items (usable)\n",
      "[2025-08-07 20:48:27] [10.1GB]    Matrix statistics: {'matrices': 3, 'metadata': 5, 'summary': 4}\n",
      "[2025-08-07 20:48:27] [10.1GB]    Usable matrices: ['matrices', 'metadata', 'summary']\n",
      "[2025-08-07 20:48:27] [10.1GB] Candidate generation engine ready with robust error handling!\n",
      "   Memory cleanup triggered at 10.1GB during engine creation\n",
      "   Memory after cleanup: 10.1GB\n"
     ]
    }
   ],
   "source": [
    "# CANDIDATE GENERATION ENGINE\n",
    "def create_candidate_generation_engine(covisit_matrices: Dict[str, Dict],\n",
    "                                     item_stats: pl.DataFrame) -> callable:\n",
    "    \"\"\"\n",
    "    Create an optimized candidate generation engine with memory efficiency and robust data handling\n",
    "\n",
    "    Args:\n",
    "        covisit_matrices: Co-visitation matrices from Part 2A\n",
    "        item_stats: Item statistics from Part 1\n",
    "\n",
    "    Returns:\n",
    "        callable: Function to generate candidates for sessions\n",
    "    \"\"\"\n",
    "    log(\"Setting up candidate generation engine...\")\n",
    "\n",
    "    # Prepare popular items for fallback with memory optimization\n",
    "    try:\n",
    "        # Get popular items by type if columns exist\n",
    "        item_columns = item_stats.columns\n",
    "\n",
    "        if \"clicks\" in item_columns and \"carts\" in item_columns and \"orders\" in item_columns:\n",
    "            popular_clicks = item_stats.sort(\"clicks\", descending=True).head(50)[\"aid\"].to_list()\n",
    "            popular_carts = item_stats.sort(\"carts\", descending=True).head(50)[\"aid\"].to_list()\n",
    "            popular_orders = item_stats.sort(\"orders\", descending=True).head(50)[\"aid\"].to_list()\n",
    "            log(f\"   Popular items prepared: {len(popular_clicks)} clicks, {len(popular_carts)} carts, {len(popular_orders)} orders\")\n",
    "        else:\n",
    "            log(\"   Type-specific popularity not available, using total_interactions...\")\n",
    "            popular_items = item_stats.sort(\"total_interactions\", descending=True).head(50)[\"aid\"].to_list()\n",
    "            popular_clicks = popular_carts = popular_orders = popular_items\n",
    "            log(f\"   Fallback popular items: {len(popular_items)} items\")\n",
    "\n",
    "    except Exception as e:\n",
    "        log(f\"   Error loading popular items: {e}\")\n",
    "        log(\"   Using fallback popular items based on item IDs...\")\n",
    "        # Emergency fallback using item stats\n",
    "        try:\n",
    "            popular_items = item_stats.head(50)[\"aid\"].to_list()\n",
    "            popular_clicks = popular_carts = popular_orders = popular_items\n",
    "            log(f\"   Emergency fallback items: {len(popular_items)} items\")\n",
    "        except:\n",
    "            # Absolute emergency fallback\n",
    "            popular_clicks = popular_carts = popular_orders = list(range(1, 51))\n",
    "            log(\"   Using absolute fallback items (1-50)\")\n",
    "\n",
    "    # Matrix statistics for monitoring with safe type checking\n",
    "    matrix_stats = {}\n",
    "    usable_matrices = {}\n",
    "\n",
    "    for name, matrix in covisit_matrices.items():\n",
    "        try:\n",
    "            if isinstance(matrix, dict):\n",
    "                matrix_stats[name] = len(matrix)\n",
    "                usable_matrices[name] = matrix\n",
    "                log(f\"   Matrix '{name}': {len(matrix)} items (usable)\")\n",
    "            elif isinstance(matrix, (list, tuple)):\n",
    "                matrix_stats[name] = len(matrix)\n",
    "                log(f\"   Matrix '{name}': {len(matrix)} items (list format - not usable for lookup)\")\n",
    "            elif isinstance(matrix, int):\n",
    "                matrix_stats[name] = matrix\n",
    "                log(f\"   Matrix '{name}': {matrix} (count format - not usable for lookup)\")\n",
    "            else:\n",
    "                matrix_stats[name] = 0\n",
    "                log(f\"   Matrix '{name}': Unknown format {type(matrix)} - not usable\")\n",
    "        except Exception as e:\n",
    "            matrix_stats[name] = 0\n",
    "            log(f\"   Matrix '{name}': Error accessing - {e}\")\n",
    "\n",
    "    log(f\"   Matrix statistics: {matrix_stats}\")\n",
    "    log(f\"   Usable matrices: {list(usable_matrices.keys())}\")\n",
    "    monitor_memory(\"candidate engine setup\")\n",
    "\n",
    "    def generate_session_candidates(session_data: pl.DataFrame) -> Dict[str, List[int]]:\n",
    "        \"\"\"\n",
    "        Generate candidates for a single session using all available strategies with robust error handling\n",
    "\n",
    "        Args:\n",
    "            session_data: DataFrame with session events (columns: session, aid, ts, type)\n",
    "\n",
    "        Returns:\n",
    "            dict: Candidates for each event type {\"clicks\": [...], \"carts\": [...], \"orders\": [...]}\n",
    "        \"\"\"\n",
    "\n",
    "        # Extract session information efficiently\n",
    "        try:\n",
    "            recent_items = session_data.sort(\"ts\", descending=True)[\"aid\"].head(15).to_list()\n",
    "            click_items = session_data.filter(pl.col(\"type\") == \"clicks\")[\"aid\"].unique().to_list()\n",
    "            buy_items = session_data.filter(pl.col(\"type\").is_in([\"carts\", \"orders\"]))[\"aid\"].unique().to_list()\n",
    "        except Exception as e:\n",
    "            # Fallback if session data is malformed\n",
    "            recent_items = session_data[\"aid\"].head(15).to_list() if \"aid\" in session_data.columns else []\n",
    "            click_items = recent_items[:10]\n",
    "            buy_items = recent_items[:5]\n",
    "\n",
    "        # Initialize candidate sets\n",
    "        candidates = {\"clicks\": set(), \"carts\": set(), \"orders\": set()}\n",
    "\n",
    "        # Strategy 1: Add recent items from session (recency boost)\n",
    "        for event_type in candidates.keys():\n",
    "            candidates[event_type].update(recent_items[:8])\n",
    "\n",
    "        # Strategy 2: Co-visitation matrix candidates with safe access\n",
    "        items_to_check = recent_items[:10]  # Focus on most recent items\n",
    "\n",
    "        for item in items_to_check:\n",
    "            # Click-to-click relationships\n",
    "            try:\n",
    "                click_matrix = usable_matrices.get(\"click_to_click\", {})\n",
    "                if isinstance(click_matrix, dict) and item in click_matrix:\n",
    "                    candidates_list = click_matrix[item]\n",
    "                    if isinstance(candidates_list, list):\n",
    "                        # Handle list of tuples (item, score)\n",
    "                        for candidate_info in candidates_list[:20]:\n",
    "                            if isinstance(candidate_info, (list, tuple)) and len(candidate_info) >= 2:\n",
    "                                candidate = candidate_info[0]\n",
    "                                candidates[\"clicks\"].add(candidate)\n",
    "                            elif isinstance(candidate_info, (int, float)):\n",
    "                                candidates[\"clicks\"].add(int(candidate_info))\n",
    "                    elif isinstance(candidates_list, dict):\n",
    "                        # Handle dictionary format\n",
    "                        for candidate in list(candidates_list.keys())[:20]:\n",
    "                            candidates[\"clicks\"].add(candidate)\n",
    "            except Exception as e:\n",
    "                pass  # Skip errors in matrix access\n",
    "\n",
    "            # Click-to-buy relationships\n",
    "            try:\n",
    "                buy_matrix = usable_matrices.get(\"click_to_buy\", {})\n",
    "                if isinstance(buy_matrix, dict) and item in buy_matrix:\n",
    "                    candidates_list = buy_matrix[item]\n",
    "                    if isinstance(candidates_list, list):\n",
    "                        for candidate_info in candidates_list[:15]:\n",
    "                            if isinstance(candidate_info, (list, tuple)) and len(candidate_info) >= 2:\n",
    "                                candidate = candidate_info[0]\n",
    "                                candidates[\"carts\"].add(candidate)\n",
    "                                candidates[\"orders\"].add(candidate)\n",
    "                            elif isinstance(candidate_info, (int, float)):\n",
    "                                candidates[\"carts\"].add(int(candidate_info))\n",
    "                                candidates[\"orders\"].add(int(candidate_info))\n",
    "                    elif isinstance(candidates_list, dict):\n",
    "                        for candidate in list(candidates_list.keys())[:15]:\n",
    "                            candidates[\"carts\"].add(candidate)\n",
    "                            candidates[\"orders\"].add(candidate)\n",
    "            except Exception as e:\n",
    "                pass  # Skip errors in matrix access\n",
    "\n",
    "        # Strategy 3: Buy-to-buy relationships (for users with purchase history)\n",
    "        if buy_items:\n",
    "            for item in buy_items[-5:]:  # Focus on recent purchases\n",
    "                try:\n",
    "                    buy2buy_matrix = usable_matrices.get(\"buy_to_buy\", {})\n",
    "                    if isinstance(buy2buy_matrix, dict) and item in buy2buy_matrix:\n",
    "                        candidates_list = buy2buy_matrix[item]\n",
    "                        if isinstance(candidates_list, list):\n",
    "                            for candidate_info in candidates_list[:12]:\n",
    "                                if isinstance(candidate_info, (list, tuple)) and len(candidate_info) >= 2:\n",
    "                                    candidate = candidate_info[0]\n",
    "                                    candidates[\"carts\"].add(candidate)\n",
    "                                    candidates[\"orders\"].add(candidate)\n",
    "                                elif isinstance(candidate_info, (int, float)):\n",
    "                                    candidates[\"carts\"].add(int(candidate_info))\n",
    "                                    candidates[\"orders\"].add(int(candidate_info))\n",
    "                        elif isinstance(candidates_list, dict):\n",
    "                            for candidate in list(candidates_list.keys())[:12]:\n",
    "                                candidates[\"carts\"].add(candidate)\n",
    "                                candidates[\"orders\"].add(candidate)\n",
    "                except Exception as e:\n",
    "                    pass  # Skip errors in matrix access\n",
    "\n",
    "        # Strategy 4: Popular items fallback\n",
    "        candidates[\"clicks\"].update(popular_clicks[:20])\n",
    "        candidates[\"carts\"].update(popular_carts[:15])\n",
    "        candidates[\"orders\"].update(popular_orders[:15])\n",
    "\n",
    "        # Strategy 5: Cross-type recommendations (clicks for carts/orders)\n",
    "        for click_item in click_items[-5:]:  # Recent clicks\n",
    "            candidates[\"carts\"].add(click_item)\n",
    "            candidates[\"orders\"].add(click_item)\n",
    "\n",
    "        # Limit and convert to lists\n",
    "        result = {}\n",
    "        for event_type, candidate_set in candidates.items():\n",
    "            result[event_type] = list(candidate_set)[:config.N_CANDIDATES]\n",
    "\n",
    "        return result\n",
    "\n",
    "    log(\"Candidate generation engine ready with robust error handling!\")\n",
    "    return generate_session_candidates\n",
    "\n",
    "# Create the candidate generation engine\n",
    "generate_candidates_func = create_candidate_generation_engine(consolidated_covisitation_matrices, item_stats)\n",
    "\n",
    "# Clean up memory after engine creation\n",
    "monitor_memory(\"engine creation\", force_cleanup=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cpZJh1vIP5zv"
   },
   "source": [
    "## MAIN CANDIDATE GENERATION PROCESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MXsSgawOP8gZ",
    "outputId": "87a5e947-9d6f-46af-8b75-4cb96d2684c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 20:48:30] [10.1GB] \n",
      "============================================================\n",
      "[2025-08-07 20:48:30] [10.1GB] STARTING CANDIDATE GENERATION\n",
      "[2025-08-07 20:48:30] [10.1GB] ============================================================\n",
      "[2025-08-07 20:48:30] [10.1GB] Generating test candidates with memory optimization...\n",
      "[2025-08-07 20:48:30] [10.1GB] Processing 1,671,803 unique test sessions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:   1%|          | 12527/1671803 [00:14<38:25, 719.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 20:48:44] [10.1GB]    Processed 12,500/1,671,803 sessions (0.7%)\n",
      "[2025-08-07 20:48:44] [10.1GB]    Current candidates: 715,149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:   1%|▏         | 25039/1671803 [00:28<39:14, 699.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 20:48:58] [10.2GB]    Processed 25,000/1,671,803 sessions (1.5%)\n",
      "[2025-08-07 20:48:58] [10.2GB]    Current candidates: 1,431,284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:   2%|▏         | 37596/1671803 [00:42<34:59, 778.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 20:49:13] [10.4GB]    Processed 37,500/1,671,803 sessions (2.2%)\n",
      "[2025-08-07 20:49:13] [10.4GB]    Current candidates: 2,145,857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:   3%|▎         | 50035/1671803 [00:57<36:37, 737.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 20:49:27] [10.5GB]    Processed 50,000/1,671,803 sessions (3.0%)\n",
      "[2025-08-07 20:49:27] [10.5GB]    Current candidates: 2,860,802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:   4%|▎         | 62572/1671803 [01:11<35:49, 748.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 20:49:41] [10.7GB]    Processed 62,500/1,671,803 sessions (3.7%)\n",
      "[2025-08-07 20:49:41] [10.7GB]    Current candidates: 3,576,502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:   4%|▍         | 75049/1671803 [01:25<36:05, 737.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 20:49:55] [10.8GB]    Processed 75,000/1,671,803 sessions (4.5%)\n",
      "[2025-08-07 20:49:55] [10.8GB]    Current candidates: 4,290,221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:   5%|▌         | 87558/1671803 [01:40<36:56, 714.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 20:50:10] [11.0GB]    Processed 87,500/1,671,803 sessions (5.2%)\n",
      "[2025-08-07 20:50:10] [11.0GB]    Current candidates: 5,004,736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:   6%|▌         | 100035/1671803 [01:54<38:35, 678.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 20:50:24] [11.1GB]    Processed 100,000/1,671,803 sessions (6.0%)\n",
      "[2025-08-07 20:50:24] [11.1GB]    Current candidates: 5,720,181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:   7%|▋         | 112523/1671803 [02:09<38:45, 670.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 20:50:39] [11.2GB]    Processed 112,500/1,671,803 sessions (6.7%)\n",
      "[2025-08-07 20:50:39] [11.2GB]    Current candidates: 6,436,271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:   7%|▋         | 125087/1671803 [02:23<35:46, 720.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 20:50:53] [11.4GB]    Processed 125,000/1,671,803 sessions (7.5%)\n",
      "[2025-08-07 20:50:53] [11.4GB]    Current candidates: 7,152,975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:   8%|▊         | 137586/1671803 [02:38<36:06, 708.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 20:51:08] [11.5GB]    Processed 137,500/1,671,803 sessions (8.2%)\n",
      "[2025-08-07 20:51:08] [11.5GB]    Current candidates: 7,867,938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:   9%|▉         | 150028/1671803 [02:52<35:32, 713.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 20:51:22] [11.6GB]    Processed 150,000/1,671,803 sessions (9.0%)\n",
      "[2025-08-07 20:51:22] [11.6GB]    Current candidates: 8,582,955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  10%|▉         | 162543/1671803 [03:06<35:48, 702.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 20:51:37] [11.8GB]    Processed 162,500/1,671,803 sessions (9.7%)\n",
      "[2025-08-07 20:51:37] [11.8GB]    Current candidates: 9,297,805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  10%|█         | 175103/1671803 [03:21<31:45, 785.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 20:51:51] [11.9GB]    Processed 175,000/1,671,803 sessions (10.5%)\n",
      "[2025-08-07 20:51:51] [11.9GB]    Current candidates: 10,012,873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  11%|█         | 187543/1671803 [03:35<34:53, 709.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 20:52:05] [12.0GB]    Processed 187,500/1,671,803 sessions (11.2%)\n",
      "[2025-08-07 20:52:05] [12.0GB]    Current candidates: 10,728,298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  12%|█▏        | 200087/1671803 [03:49<34:46, 705.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 20:52:19] [12.2GB]    Processed 200,000/1,671,803 sessions (12.0%)\n",
      "[2025-08-07 20:52:19] [12.2GB]    Current candidates: 11,443,486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  13%|█▎        | 212517/1671803 [04:03<33:28, 726.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 20:52:33] [12.3GB]    Processed 212,500/1,671,803 sessions (12.7%)\n",
      "[2025-08-07 20:52:33] [12.3GB]    Current candidates: 12,158,431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  13%|█▎        | 225049/1671803 [04:17<33:59, 709.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 20:52:47] [12.4GB]    Processed 225,000/1,671,803 sessions (13.5%)\n",
      "[2025-08-07 20:52:47] [12.4GB]    Current candidates: 12,872,827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  14%|█▍        | 237528/1671803 [04:31<34:01, 702.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 20:53:02] [12.6GB]    Processed 237,500/1,671,803 sessions (14.2%)\n",
      "[2025-08-07 20:53:02] [12.6GB]    Current candidates: 13,587,898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  15%|█▍        | 250065/1671803 [04:46<32:22, 731.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 20:53:16] [12.7GB]    Processed 250,000/1,671,803 sessions (15.0%)\n",
      "[2025-08-07 20:53:16] [12.7GB]    Current candidates: 14,302,841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  16%|█▌        | 262601/1671803 [05:00<29:50, 786.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 20:53:30] [12.9GB]    Processed 262,500/1,671,803 sessions (15.7%)\n",
      "[2025-08-07 20:53:30] [12.9GB]    Current candidates: 15,018,111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  16%|█▋        | 275085/1671803 [05:14<31:38, 735.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 20:53:44] [13.0GB]    Processed 275,000/1,671,803 sessions (16.4%)\n",
      "[2025-08-07 20:53:44] [13.0GB]    Current candidates: 15,732,881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  17%|█▋        | 287585/1671803 [05:28<30:56, 745.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 20:53:58] [13.1GB]    Processed 287,500/1,671,803 sessions (17.2%)\n",
      "[2025-08-07 20:53:58] [13.1GB]    Current candidates: 16,448,429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  18%|█▊        | 300013/1671803 [05:42<30:39, 745.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 20:54:12] [13.2GB]    Processed 300,000/1,671,803 sessions (17.9%)\n",
      "[2025-08-07 20:54:12] [13.2GB]    Current candidates: 17,164,443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  19%|█▊        | 312525/1671803 [05:56<31:53, 710.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 20:54:26] [13.4GB]    Processed 312,500/1,671,803 sessions (18.7%)\n",
      "[2025-08-07 20:54:26] [13.4GB]    Current candidates: 17,880,354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  19%|█▉        | 325078/1671803 [06:10<30:20, 739.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 20:54:40] [13.5GB]    Processed 325,000/1,671,803 sessions (19.4%)\n",
      "[2025-08-07 20:54:40] [13.5GB]    Current candidates: 18,595,506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  20%|██        | 337572/1671803 [06:24<30:04, 739.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 20:54:54] [13.7GB]    Processed 337,500/1,671,803 sessions (20.2%)\n",
      "[2025-08-07 20:54:54] [13.7GB]    Current candidates: 19,311,266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  21%|██        | 350025/1671803 [06:38<30:56, 712.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 20:55:08] [13.8GB]    Processed 350,000/1,671,803 sessions (20.9%)\n",
      "[2025-08-07 20:55:08] [13.8GB]    Current candidates: 20,027,404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  22%|██▏       | 362592/1671803 [06:52<29:18, 744.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 20:55:22] [13.9GB]    Processed 362,500/1,671,803 sessions (21.7%)\n",
      "[2025-08-07 20:55:22] [13.9GB]    Current candidates: 20,743,692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  22%|██▏       | 375033/1671803 [07:06<30:58, 697.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 20:55:37] [14.1GB]    Processed 375,000/1,671,803 sessions (22.4%)\n",
      "[2025-08-07 20:55:37] [14.1GB]    Current candidates: 21,460,485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  23%|██▎       | 387583/1671803 [07:21<29:36, 723.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 20:55:51] [14.2GB]    Processed 387,500/1,671,803 sessions (23.2%)\n",
      "[2025-08-07 20:55:51] [14.2GB]    Current candidates: 22,175,625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  24%|██▍       | 400014/1671803 [07:35<29:47, 711.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 20:56:05] [14.3GB]    Processed 400,000/1,671,803 sessions (23.9%)\n",
      "[2025-08-07 20:56:05] [14.3GB]    Current candidates: 22,890,957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  25%|██▍       | 412555/1671803 [07:49<28:00, 749.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 20:56:19] [14.5GB]    Processed 412,500/1,671,803 sessions (24.7%)\n",
      "[2025-08-07 20:56:19] [14.5GB]    Current candidates: 23,606,136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  25%|██▌       | 425041/1671803 [08:03<28:24, 731.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 20:56:33] [14.6GB]    Processed 425,000/1,671,803 sessions (25.4%)\n",
      "[2025-08-07 20:56:33] [14.6GB]    Current candidates: 24,320,677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  26%|██▌       | 437551/1671803 [08:17<28:57, 710.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 20:56:47] [14.7GB]    Processed 437,500/1,671,803 sessions (26.2%)\n",
      "[2025-08-07 20:56:47] [14.7GB]    Current candidates: 25,036,226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  27%|██▋       | 450078/1671803 [08:31<27:51, 730.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 20:57:01] [14.9GB]    Processed 450,000/1,671,803 sessions (26.9%)\n",
      "[2025-08-07 20:57:01] [14.9GB]    Current candidates: 25,751,762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  28%|██▊       | 462601/1671803 [08:45<25:47, 781.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 20:57:15] [15.0GB]    Processed 462,500/1,671,803 sessions (27.7%)\n",
      "[2025-08-07 20:57:15] [15.0GB]    Current candidates: 26,466,799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  28%|██▊       | 475039/1671803 [08:59<29:30, 676.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 20:57:29] [15.2GB]    Processed 475,000/1,671,803 sessions (28.4%)\n",
      "[2025-08-07 20:57:29] [15.2GB]    Current candidates: 27,182,626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  29%|██▉       | 487571/1671803 [09:13<26:22, 748.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 20:57:43] [15.3GB]    Processed 487,500/1,671,803 sessions (29.2%)\n",
      "[2025-08-07 20:57:43] [15.3GB]    Current candidates: 27,899,012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  30%|██▉       | 500012/1671803 [09:27<27:37, 706.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 20:57:57] [15.4GB]    Processed 500,000/1,671,803 sessions (29.9%)\n",
      "[2025-08-07 20:57:57] [15.4GB]    Current candidates: 28,615,211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  31%|███       | 512534/1671803 [09:41<26:15, 735.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 20:58:11] [15.6GB]    Processed 512,500/1,671,803 sessions (30.7%)\n",
      "[2025-08-07 20:58:11] [15.6GB]    Current candidates: 29,330,739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  31%|███▏      | 525049/1671803 [09:55<25:31, 748.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 20:58:25] [15.7GB]    Processed 525,000/1,671,803 sessions (31.4%)\n",
      "[2025-08-07 20:58:25] [15.7GB]    Current candidates: 30,046,305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  32%|███▏      | 537516/1671803 [10:09<24:44, 764.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 20:58:39] [15.8GB]    Processed 537,500/1,671,803 sessions (32.2%)\n",
      "[2025-08-07 20:58:39] [15.8GB]    Current candidates: 30,762,121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  33%|███▎      | 550055/1671803 [10:23<25:24, 735.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 20:58:53] [15.9GB]    Processed 550,000/1,671,803 sessions (32.9%)\n",
      "[2025-08-07 20:58:53] [15.9GB]    Current candidates: 31,478,004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  34%|███▎      | 562585/1671803 [10:37<25:19, 730.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 20:59:07] [16.1GB]    Processed 562,500/1,671,803 sessions (33.6%)\n",
      "[2025-08-07 20:59:07] [16.1GB]    Current candidates: 32,193,585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  34%|███▍      | 575066/1671803 [10:51<24:47, 737.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 20:59:21] [16.2GB]    Processed 575,000/1,671,803 sessions (34.4%)\n",
      "[2025-08-07 20:59:21] [16.2GB]    Current candidates: 32,907,332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  35%|███▌      | 587553/1671803 [11:05<25:37, 705.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 20:59:35] [16.4GB]    Processed 587,500/1,671,803 sessions (35.1%)\n",
      "[2025-08-07 20:59:35] [16.4GB]    Current candidates: 33,624,581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  36%|███▌      | 600081/1671803 [11:19<24:02, 742.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 20:59:49] [16.5GB]    Processed 600,000/1,671,803 sessions (35.9%)\n",
      "[2025-08-07 20:59:49] [16.5GB]    Current candidates: 34,339,974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  37%|███▋      | 612596/1671803 [11:34<23:02, 766.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:00:04] [16.6GB]    Processed 612,500/1,671,803 sessions (36.6%)\n",
      "[2025-08-07 21:00:04] [16.6GB]    Current candidates: 35,055,518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  37%|███▋      | 625096/1671803 [11:48<22:34, 772.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:00:18] [16.8GB]    Processed 625,000/1,671,803 sessions (37.4%)\n",
      "[2025-08-07 21:00:18] [16.8GB]    Current candidates: 35,771,145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  38%|███▊      | 637581/1671803 [12:02<24:42, 697.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:00:32] [16.9GB]    Processed 637,500/1,671,803 sessions (38.1%)\n",
      "[2025-08-07 21:00:32] [16.9GB]    Current candidates: 36,486,470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  39%|███▉      | 650025/1671803 [12:17<25:15, 674.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:00:47] [17.0GB]    Processed 650,000/1,671,803 sessions (38.9%)\n",
      "[2025-08-07 21:00:47] [17.0GB]    Current candidates: 37,201,682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  40%|███▉      | 662524/1671803 [12:31<22:50, 736.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:01:02] [17.2GB]    Processed 662,500/1,671,803 sessions (39.6%)\n",
      "[2025-08-07 21:01:02] [17.2GB]    Current candidates: 37,916,416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  40%|████      | 675088/1671803 [12:46<23:12, 715.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:01:16] [17.3GB]    Processed 675,000/1,671,803 sessions (40.4%)\n",
      "[2025-08-07 21:01:16] [17.3GB]    Current candidates: 38,632,210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  41%|████      | 687585/1671803 [13:00<23:29, 698.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:01:30] [17.4GB]    Processed 687,500/1,671,803 sessions (41.1%)\n",
      "[2025-08-07 21:01:30] [17.4GB]    Current candidates: 39,347,538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  42%|████▏     | 700089/1671803 [13:14<22:37, 715.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:01:44] [17.6GB]    Processed 700,000/1,671,803 sessions (41.9%)\n",
      "[2025-08-07 21:01:44] [17.6GB]    Current candidates: 40,063,670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  43%|████▎     | 712546/1671803 [13:28<22:32, 709.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:01:58] [17.7GB]    Processed 712,500/1,671,803 sessions (42.6%)\n",
      "[2025-08-07 21:01:58] [17.7GB]    Current candidates: 40,779,227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  43%|████▎     | 725089/1671803 [13:43<20:35, 766.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:02:13] [17.9GB]    Processed 725,000/1,671,803 sessions (43.4%)\n",
      "[2025-08-07 21:02:13] [17.9GB]    Current candidates: 41,494,105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  44%|████▍     | 737564/1671803 [13:57<21:11, 735.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:02:27] [18.0GB]    Processed 737,500/1,671,803 sessions (44.1%)\n",
      "[2025-08-07 21:02:27] [18.0GB]    Current candidates: 42,208,476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  45%|████▍     | 750023/1671803 [14:11<20:54, 734.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:02:41] [18.1GB]    Processed 750,000/1,671,803 sessions (44.9%)\n",
      "[2025-08-07 21:02:41] [18.1GB]    Current candidates: 42,922,119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  46%|████▌     | 762562/1671803 [14:25<20:29, 739.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:02:55] [18.2GB]    Processed 762,500/1,671,803 sessions (45.6%)\n",
      "[2025-08-07 21:02:55] [18.2GB]    Current candidates: 43,637,101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  46%|████▋     | 775058/1671803 [14:39<20:36, 725.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:03:09] [18.4GB]    Processed 775,000/1,671,803 sessions (46.4%)\n",
      "[2025-08-07 21:03:09] [18.4GB]    Current candidates: 44,352,636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  47%|████▋     | 787564/1671803 [14:53<20:02, 735.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:03:24] [18.5GB]    Processed 787,500/1,671,803 sessions (47.1%)\n",
      "[2025-08-07 21:03:24] [18.5GB]    Current candidates: 45,068,510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  48%|████▊     | 800086/1671803 [15:08<19:57, 728.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:03:38] [18.7GB]    Processed 800,000/1,671,803 sessions (47.9%)\n",
      "[2025-08-07 21:03:38] [18.7GB]    Current candidates: 45,784,211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  49%|████▊     | 812588/1671803 [15:22<19:25, 737.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:03:52] [18.8GB]    Processed 812,500/1,671,803 sessions (48.6%)\n",
      "[2025-08-07 21:03:52] [18.8GB]    Current candidates: 46,499,289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  49%|████▉     | 825104/1671803 [15:36<17:48, 792.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:04:06] [18.9GB]    Processed 825,000/1,671,803 sessions (49.3%)\n",
      "[2025-08-07 21:04:06] [18.9GB]    Current candidates: 47,215,453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  50%|█████     | 837601/1671803 [15:50<17:49, 780.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:04:20] [19.1GB]    Processed 837,500/1,671,803 sessions (50.1%)\n",
      "[2025-08-07 21:04:20] [19.1GB]    Current candidates: 47,930,385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  51%|█████     | 850095/1671803 [16:04<18:14, 750.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:04:34] [19.2GB]    Processed 850,000/1,671,803 sessions (50.8%)\n",
      "[2025-08-07 21:04:34] [19.2GB]    Current candidates: 48,646,390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  52%|█████▏    | 862570/1671803 [16:18<19:31, 690.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:04:48] [19.3GB]    Processed 862,500/1,671,803 sessions (51.6%)\n",
      "[2025-08-07 21:04:48] [19.3GB]    Current candidates: 49,362,014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  52%|█████▏    | 875031/1671803 [16:32<18:33, 715.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:05:03] [19.5GB]    Processed 875,000/1,671,803 sessions (52.3%)\n",
      "[2025-08-07 21:05:03] [19.5GB]    Current candidates: 50,076,935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  53%|█████▎    | 887582/1671803 [16:48<19:49, 659.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:05:18] [19.6GB]    Processed 887,500/1,671,803 sessions (53.1%)\n",
      "[2025-08-07 21:05:18] [19.6GB]    Current candidates: 50,791,382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  54%|█████▍    | 900063/1671803 [17:05<20:25, 629.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:05:35] [19.7GB]    Processed 900,000/1,671,803 sessions (53.8%)\n",
      "[2025-08-07 21:05:35] [19.7GB]    Current candidates: 51,505,815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  55%|█████▍    | 912567/1671803 [17:22<22:09, 571.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:05:53] [19.9GB]    Processed 912,500/1,671,803 sessions (54.6%)\n",
      "[2025-08-07 21:05:53] [19.9GB]    Current candidates: 52,222,116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  55%|█████▌    | 925027/1671803 [17:43<23:31, 528.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:06:13] [20.0GB]    Processed 925,000/1,671,803 sessions (55.3%)\n",
      "[2025-08-07 21:06:13] [20.0GB]    Current candidates: 52,937,309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  56%|█████▌    | 937566/1671803 [18:03<24:06, 507.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:06:34] [20.1GB]    Processed 937,500/1,671,803 sessions (56.1%)\n",
      "[2025-08-07 21:06:34] [20.1GB]    Current candidates: 53,651,470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  57%|█████▋    | 950024/1671803 [18:22<20:20, 591.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:06:52] [20.3GB]    Processed 950,000/1,671,803 sessions (56.8%)\n",
      "[2025-08-07 21:06:52] [20.3GB]    Current candidates: 54,367,210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  58%|█████▊    | 962555/1671803 [18:41<20:56, 564.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:07:11] [20.4GB]    Processed 962,500/1,671,803 sessions (57.6%)\n",
      "[2025-08-07 21:07:11] [20.4GB]    Current candidates: 55,081,579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  58%|█████▊    | 975033/1671803 [18:57<18:07, 640.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:07:27] [20.5GB]    Processed 975,000/1,671,803 sessions (58.3%)\n",
      "[2025-08-07 21:07:27] [20.5GB]    Current candidates: 55,796,909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  59%|█████▉    | 987524/1671803 [19:12<16:46, 679.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:07:42] [20.7GB]    Processed 987,500/1,671,803 sessions (59.1%)\n",
      "[2025-08-07 21:07:42] [20.7GB]    Current candidates: 56,513,289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  60%|█████▉    | 1000067/1671803 [19:27<16:35, 674.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:07:57] [20.8GB]    Processed 1,000,000/1,671,803 sessions (59.8%)\n",
      "[2025-08-07 21:07:57] [20.8GB]    Current candidates: 57,227,974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  61%|██████    | 1012588/1671803 [19:43<16:00, 686.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:08:13] [20.9GB]    Processed 1,012,500/1,671,803 sessions (60.6%)\n",
      "[2025-08-07 21:08:13] [20.9GB]    Current candidates: 57,942,827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  61%|██████▏   | 1025060/1671803 [19:58<17:06, 630.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:08:28] [21.1GB]    Processed 1,025,000/1,671,803 sessions (61.3%)\n",
      "[2025-08-07 21:08:28] [21.1GB]    Current candidates: 58,657,571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  62%|██████▏   | 1037522/1671803 [20:13<15:40, 674.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:08:43] [21.2GB]    Processed 1,037,500/1,671,803 sessions (62.1%)\n",
      "[2025-08-07 21:08:43] [21.2GB]    Current candidates: 59,372,191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  63%|██████▎   | 1050079/1671803 [20:28<15:03, 688.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:08:59] [21.4GB]    Processed 1,050,000/1,671,803 sessions (62.8%)\n",
      "[2025-08-07 21:08:59] [21.4GB]    Current candidates: 60,088,178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  64%|██████▎   | 1062534/1671803 [20:44<16:01, 633.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:09:14] [21.5GB]    Processed 1,062,500/1,671,803 sessions (63.6%)\n",
      "[2025-08-07 21:09:14] [21.5GB]    Current candidates: 60,803,585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  64%|██████▍   | 1075081/1671803 [20:59<14:30, 685.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:09:29] [21.6GB]    Processed 1,075,000/1,671,803 sessions (64.3%)\n",
      "[2025-08-07 21:09:29] [21.6GB]    Current candidates: 61,519,857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  65%|██████▌   | 1087594/1671803 [21:14<13:18, 731.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:09:44] [21.8GB]    Processed 1,087,500/1,671,803 sessions (65.0%)\n",
      "[2025-08-07 21:09:44] [21.8GB]    Current candidates: 62,235,785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  66%|██████▌   | 1100047/1671803 [21:29<14:27, 658.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:09:59] [21.9GB]    Processed 1,100,000/1,671,803 sessions (65.8%)\n",
      "[2025-08-07 21:09:59] [21.9GB]    Current candidates: 62,950,688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  67%|██████▋   | 1112545/1671803 [21:45<15:37, 596.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:10:16] [22.0GB]    Processed 1,112,500/1,671,803 sessions (66.5%)\n",
      "[2025-08-07 21:10:16] [22.0GB]    Current candidates: 63,665,721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  67%|██████▋   | 1125046/1671803 [22:02<14:41, 620.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:10:32] [22.2GB]    Processed 1,125,000/1,671,803 sessions (67.3%)\n",
      "[2025-08-07 21:10:32] [22.2GB]    Current candidates: 64,380,580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  68%|██████▊   | 1137559/1671803 [22:17<13:20, 667.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:10:48] [22.3GB]    Processed 1,137,500/1,671,803 sessions (68.0%)\n",
      "[2025-08-07 21:10:48] [22.3GB]    Current candidates: 65,097,329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  69%|██████▉   | 1150014/1671803 [22:33<13:27, 645.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:11:03] [22.4GB]    Processed 1,150,000/1,671,803 sessions (68.8%)\n",
      "[2025-08-07 21:11:03] [22.4GB]    Current candidates: 65,812,964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  70%|██████▉   | 1162538/1671803 [22:49<13:48, 614.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:11:19] [22.6GB]    Processed 1,162,500/1,671,803 sessions (69.5%)\n",
      "[2025-08-07 21:11:19] [22.6GB]    Current candidates: 66,527,652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  70%|███████   | 1175045/1671803 [23:05<12:32, 659.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:11:35] [22.7GB]    Processed 1,175,000/1,671,803 sessions (70.3%)\n",
      "[2025-08-07 21:11:35] [22.7GB]    Current candidates: 67,242,617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  71%|███████   | 1187512/1671803 [23:21<11:53, 678.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:11:51] [22.8GB]    Processed 1,187,500/1,671,803 sessions (71.0%)\n",
      "[2025-08-07 21:11:51] [22.8GB]    Current candidates: 67,958,471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  72%|███████▏  | 1200042/1671803 [23:37<12:38, 621.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:12:07] [23.0GB]    Processed 1,200,000/1,671,803 sessions (71.8%)\n",
      "[2025-08-07 21:12:07] [23.0GB]    Current candidates: 68,673,655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  73%|███████▎  | 1212585/1671803 [23:52<11:00, 695.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:12:22] [23.1GB]    Processed 1,212,500/1,671,803 sessions (72.5%)\n",
      "[2025-08-07 21:12:22] [23.1GB]    Current candidates: 69,388,964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  73%|███████▎  | 1225041/1671803 [24:07<11:15, 661.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:12:37] [23.2GB]    Processed 1,225,000/1,671,803 sessions (73.3%)\n",
      "[2025-08-07 21:12:37] [23.2GB]    Current candidates: 70,105,466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  74%|███████▍  | 1237587/1671803 [24:23<10:38, 680.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:12:53] [23.4GB]    Processed 1,237,500/1,671,803 sessions (74.0%)\n",
      "[2025-08-07 21:12:53] [23.4GB]    Current candidates: 70,821,281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  75%|███████▍  | 1250070/1671803 [24:38<10:40, 658.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:13:08] [23.5GB]    Processed 1,250,000/1,671,803 sessions (74.8%)\n",
      "[2025-08-07 21:13:08] [23.5GB]    Current candidates: 71,537,160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  76%|███████▌  | 1262560/1671803 [24:54<10:32, 647.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:13:24] [23.6GB]    Processed 1,262,500/1,671,803 sessions (75.5%)\n",
      "[2025-08-07 21:13:24] [23.6GB]    Current candidates: 72,253,347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  76%|███████▋  | 1275070/1671803 [25:09<10:19, 640.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:13:40] [23.8GB]    Processed 1,275,000/1,671,803 sessions (76.3%)\n",
      "[2025-08-07 21:13:40] [23.8GB]    Current candidates: 72,969,206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  77%|███████▋  | 1287549/1671803 [25:25<09:33, 669.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:13:55] [23.9GB]    Processed 1,287,500/1,671,803 sessions (77.0%)\n",
      "[2025-08-07 21:13:55] [23.9GB]    Current candidates: 73,685,206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  78%|███████▊  | 1300029/1671803 [25:40<09:48, 631.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:14:10] [24.0GB]    Processed 1,300,000/1,671,803 sessions (77.8%)\n",
      "[2025-08-07 21:14:10] [24.0GB]    Current candidates: 74,402,205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  79%|███████▊  | 1312524/1671803 [25:56<09:20, 640.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:14:26] [24.2GB]    Processed 1,312,500/1,671,803 sessions (78.5%)\n",
      "[2025-08-07 21:14:26] [24.2GB]    Current candidates: 75,118,076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  79%|███████▉  | 1325084/1671803 [26:12<08:24, 687.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:14:42] [24.3GB]    Processed 1,325,000/1,671,803 sessions (79.3%)\n",
      "[2025-08-07 21:14:42] [24.3GB]    Current candidates: 75,834,242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  80%|████████  | 1337525/1671803 [26:27<08:39, 643.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:14:57] [24.5GB]    Processed 1,337,500/1,671,803 sessions (80.0%)\n",
      "[2025-08-07 21:14:57] [24.5GB]    Current candidates: 76,551,714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  81%|████████  | 1350041/1671803 [26:42<07:59, 671.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:15:12] [24.6GB]    Processed 1,350,000/1,671,803 sessions (80.8%)\n",
      "[2025-08-07 21:15:12] [24.6GB]    Current candidates: 77,267,866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  81%|████████▏ | 1362516/1671803 [26:58<07:39, 673.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:15:28] [24.7GB]    Processed 1,362,500/1,671,803 sessions (81.5%)\n",
      "[2025-08-07 21:15:28] [24.7GB]    Current candidates: 77,982,427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  82%|████████▏ | 1375017/1671803 [27:13<07:15, 682.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:15:43] [24.9GB]    Processed 1,375,000/1,671,803 sessions (82.2%)\n",
      "[2025-08-07 21:15:43] [24.9GB]    Current candidates: 78,698,132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  83%|████████▎ | 1387566/1671803 [27:28<06:49, 694.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:15:58] [25.0GB]    Processed 1,387,500/1,671,803 sessions (83.0%)\n",
      "[2025-08-07 21:15:58] [25.0GB]    Current candidates: 79,413,460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  84%|████████▎ | 1400048/1671803 [27:42<06:35, 687.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:16:13] [25.1GB]    Processed 1,400,000/1,671,803 sessions (83.7%)\n",
      "[2025-08-07 21:16:13] [25.1GB]    Current candidates: 80,130,067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  84%|████████▍ | 1412514/1671803 [27:57<06:26, 670.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:16:28] [25.3GB]    Processed 1,412,500/1,671,803 sessions (84.5%)\n",
      "[2025-08-07 21:16:28] [25.3GB]    Current candidates: 80,843,341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  85%|████████▌ | 1425086/1671803 [28:13<05:45, 714.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:16:43] [25.4GB]    Processed 1,425,000/1,671,803 sessions (85.2%)\n",
      "[2025-08-07 21:16:43] [25.4GB]    Current candidates: 81,559,095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  86%|████████▌ | 1437560/1671803 [28:28<05:40, 687.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:16:58] [25.5GB]    Processed 1,437,500/1,671,803 sessions (86.0%)\n",
      "[2025-08-07 21:16:58] [25.5GB]    Current candidates: 82,274,650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  87%|████████▋ | 1450022/1671803 [28:42<05:13, 708.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:17:13] [25.7GB]    Processed 1,450,000/1,671,803 sessions (86.7%)\n",
      "[2025-08-07 21:17:13] [25.7GB]    Current candidates: 82,989,680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  87%|████████▋ | 1462525/1671803 [28:57<05:07, 680.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:17:27] [25.8GB]    Processed 1,462,500/1,671,803 sessions (87.5%)\n",
      "[2025-08-07 21:17:27] [25.8GB]    Current candidates: 83,705,506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  88%|████████▊ | 1475029/1671803 [29:12<04:44, 690.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:17:42] [25.9GB]    Processed 1,475,000/1,671,803 sessions (88.2%)\n",
      "[2025-08-07 21:17:42] [25.9GB]    Current candidates: 84,420,545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  89%|████████▉ | 1487579/1671803 [29:27<04:36, 665.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:17:57] [26.1GB]    Processed 1,487,500/1,671,803 sessions (89.0%)\n",
      "[2025-08-07 21:17:57] [26.1GB]    Current candidates: 85,136,751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  90%|████████▉ | 1500058/1671803 [29:42<04:03, 706.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:18:12] [26.2GB]    Processed 1,500,000/1,671,803 sessions (89.7%)\n",
      "[2025-08-07 21:18:12] [26.2GB]    Current candidates: 85,852,187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  90%|█████████ | 1512549/1671803 [29:57<03:53, 680.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:18:27] [26.3GB]    Processed 1,512,500/1,671,803 sessions (90.5%)\n",
      "[2025-08-07 21:18:27] [26.3GB]    Current candidates: 86,568,622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  91%|█████████ | 1525076/1671803 [30:12<03:41, 663.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:18:42] [26.5GB]    Processed 1,525,000/1,671,803 sessions (91.2%)\n",
      "[2025-08-07 21:18:42] [26.5GB]    Current candidates: 87,283,561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  92%|█████████▏| 1537531/1671803 [30:27<03:13, 692.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:18:57] [26.6GB]    Processed 1,537,500/1,671,803 sessions (92.0%)\n",
      "[2025-08-07 21:18:57] [26.6GB]    Current candidates: 87,998,711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  93%|█████████▎| 1550032/1671803 [30:41<03:04, 658.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:19:12] [26.8GB]    Processed 1,550,000/1,671,803 sessions (92.7%)\n",
      "[2025-08-07 21:19:12] [26.8GB]    Current candidates: 88,714,049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  93%|█████████▎| 1562532/1671803 [30:57<02:48, 649.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:19:27] [26.9GB]    Processed 1,562,500/1,671,803 sessions (93.5%)\n",
      "[2025-08-07 21:19:27] [26.9GB]    Current candidates: 89,429,568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  94%|█████████▍| 1575028/1671803 [31:11<02:17, 704.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:19:42] [27.0GB]    Processed 1,575,000/1,671,803 sessions (94.2%)\n",
      "[2025-08-07 21:19:42] [27.0GB]    Current candidates: 90,145,283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  95%|█████████▍| 1587536/1671803 [31:26<02:04, 674.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:19:56] [27.2GB]    Processed 1,587,500/1,671,803 sessions (95.0%)\n",
      "[2025-08-07 21:19:56] [27.2GB]    Current candidates: 90,861,274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  96%|█████████▌| 1600026/1671803 [31:41<01:45, 681.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:20:11] [27.3GB]    Processed 1,600,000/1,671,803 sessions (95.7%)\n",
      "[2025-08-07 21:20:11] [27.3GB]    Current candidates: 91,575,854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  96%|█████████▋| 1612584/1671803 [31:58<01:26, 685.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:20:28] [27.4GB]    Processed 1,612,500/1,671,803 sessions (96.5%)\n",
      "[2025-08-07 21:20:28] [27.4GB]    Current candidates: 92,291,055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  97%|█████████▋| 1625066/1671803 [32:14<01:20, 580.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:20:44] [27.6GB]    Processed 1,625,000/1,671,803 sessions (97.2%)\n",
      "[2025-08-07 21:20:44] [27.6GB]    Current candidates: 93,005,917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  98%|█████████▊| 1637573/1671803 [32:30<00:53, 639.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:21:00] [27.7GB]    Processed 1,637,500/1,671,803 sessions (97.9%)\n",
      "[2025-08-07 21:21:00] [27.7GB]    Current candidates: 93,723,091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  99%|█████████▊| 1650057/1671803 [32:46<00:36, 602.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:21:17] [27.8GB]    Processed 1,650,000/1,671,803 sessions (98.7%)\n",
      "[2025-08-07 21:21:17] [27.8GB]    Current candidates: 94,437,912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates:  99%|█████████▉| 1662560/1671803 [33:03<00:16, 569.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:21:33] [28.0GB]    Processed 1,662,500/1,671,803 sessions (99.4%)\n",
      "[2025-08-07 21:21:33] [28.0GB]    Current candidates: 95,154,219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating candidates: 100%|██████████| 1671803/1671803 [33:15<00:00, 837.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:21:45] [28.1GB] Converting candidates to DataFrame...\n",
      "[2025-08-07 21:22:37] [31.2GB] Generated 95,687,062 total candidates\n",
      "   Memory cleanup triggered at 13.5GB during candidate generation completion\n",
      "   Memory after cleanup: 13.5GB\n",
      "[2025-08-07 21:22:47] [13.5GB] Candidate generation completed successfully!\n",
      "[2025-08-07 21:22:47] [13.5GB] Generated 95,687,062 total candidates\n",
      "[2025-08-07 21:22:47] [13.5GB] Candidate generation validation passed!\n",
      "[2025-08-07 21:22:47] [13.5GB] Final candidate count: 95,687,062\n",
      "   Memory cleanup triggered at 13.4GB during after candidate generation\n",
      "   Memory after cleanup: 13.4GB\n"
     ]
    }
   ],
   "source": [
    "def generate_test_candidates(test_df: pl.DataFrame,\n",
    "                           candidate_func: callable) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate candidates for all test sessions using chunked processing\n",
    "\n",
    "    Args:\n",
    "        test_df: Test data\n",
    "        candidate_func: Function to generate candidates for sessions\n",
    "\n",
    "    Returns:\n",
    "        pl.DataFrame: All generated candidates\n",
    "    \"\"\"\n",
    "    log(\"Generating test candidates with memory optimization...\")\n",
    "\n",
    "    # Get unique sessions for processing\n",
    "    unique_sessions = test_df.select(\"session\").unique().to_pandas()[\"session\"].tolist()\n",
    "    total_sessions = len(unique_sessions)\n",
    "    log(f\"Processing {total_sessions:,} unique test sessions\")\n",
    "\n",
    "    # Initialize results list\n",
    "    all_candidates = []\n",
    "\n",
    "    # Process sessions in chunks\n",
    "    chunk_count = 0\n",
    "    processed_sessions = 0\n",
    "\n",
    "    with tqdm(total=total_sessions, desc=\"Generating candidates\") as pbar:\n",
    "        for i in range(0, total_sessions, config.CHUNK_SIZE):\n",
    "            chunk_sessions = unique_sessions[i:i + config.CHUNK_SIZE]\n",
    "            chunk_count += 1\n",
    "\n",
    "            # Get session data for this chunk\n",
    "            chunk_data = test_df.filter(pl.col(\"session\").is_in(chunk_sessions))\n",
    "\n",
    "            # Process each session in the chunk\n",
    "            for session_id in chunk_sessions:\n",
    "                session_data = chunk_data.filter(pl.col(\"session\") == session_id)\n",
    "\n",
    "                if len(session_data) > 0:\n",
    "                    # Generate candidates for this session\n",
    "                    session_candidates = candidate_func(session_data)\n",
    "\n",
    "                    # Convert to records\n",
    "                    for event_type, candidates_list in session_candidates.items():\n",
    "                        for aid in candidates_list:\n",
    "                            all_candidates.append({\n",
    "                                \"session\": session_id,\n",
    "                                \"type\": event_type,\n",
    "                                \"aid\": aid\n",
    "                            })\n",
    "\n",
    "                processed_sessions += 1\n",
    "                pbar.update(1)\n",
    "\n",
    "            # Memory management\n",
    "            if chunk_count % config.GC_FREQUENCY == 0:\n",
    "                monitor_memory(f\"chunk {chunk_count}\")\n",
    "\n",
    "            # Progress update\n",
    "            if chunk_count % config.PROGRESS_UPDATE == 0:\n",
    "                log(f\"   Processed {processed_sessions:,}/{total_sessions:,} sessions ({processed_sessions/total_sessions*100:.1f}%)\")\n",
    "                log(f\"   Current candidates: {len(all_candidates):,}\")\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    log(\"Converting candidates to DataFrame...\")\n",
    "    if all_candidates:\n",
    "        candidates_df = pl.DataFrame(all_candidates)\n",
    "        log(f\"Generated {len(candidates_df):,} total candidates\")\n",
    "    else:\n",
    "        log(\"No candidates generated! Creating empty DataFrame...\")\n",
    "        candidates_df = pl.DataFrame({\n",
    "            \"session\": [],\n",
    "            \"type\": [],\n",
    "            \"aid\": []\n",
    "        })\n",
    "\n",
    "    # Final memory cleanup\n",
    "    del all_candidates\n",
    "    monitor_memory(\"candidate generation completion\", force_cleanup=True)\n",
    "\n",
    "    return candidates_df\n",
    "\n",
    "# Generate candidates\n",
    "log(\"\\n\" + \"=\"*60)\n",
    "log(\"STARTING CANDIDATE GENERATION\")\n",
    "log(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    test_candidates = generate_test_candidates(test_df, generate_candidates_func)\n",
    "    log(\"Candidate generation completed successfully!\")\n",
    "    log(f\"Generated {len(test_candidates):,} total candidates\")\n",
    "\n",
    "    # Verify the result\n",
    "    if test_candidates is None or len(test_candidates) == 0:\n",
    "        raise ValueError(\"Candidate generation returned empty results\")\n",
    "\n",
    "    # Check if required columns exist\n",
    "    required_columns = ['session', 'type', 'aid']\n",
    "    missing_columns = [col for col in required_columns if col not in test_candidates.columns]\n",
    "    if missing_columns:\n",
    "        raise ValueError(f\"Missing required columns in candidates: {missing_columns}\")\n",
    "\n",
    "    log(\"Candidate generation validation passed!\")\n",
    "\n",
    "except Exception as e:\n",
    "    log(f\"Error in candidate generation: {e}\")\n",
    "    log(\"Creating emergency fallback candidates...\")\n",
    "\n",
    "    # Emergency fallback: create minimal candidates\n",
    "    try:\n",
    "        # Get unique sessions from test data\n",
    "        unique_sessions = test_df.select(\"session\").unique().to_pandas()[\"session\"].tolist()\n",
    "        log(f\"Creating fallback candidates for {len(unique_sessions):,} sessions\")\n",
    "\n",
    "        # Get some popular items for fallback\n",
    "        try:\n",
    "            popular_items = item_stats.head(20)[\"aid\"].to_list()\n",
    "        except:\n",
    "            popular_items = list(range(1, 21))  # Absolute fallback\n",
    "\n",
    "        # Create fallback candidates efficiently\n",
    "        fallback_data = []\n",
    "        for session_id in unique_sessions[:1000]:  # Limit for memory\n",
    "            for event_type in [\"clicks\", \"carts\", \"orders\"]:\n",
    "                for aid in popular_items:\n",
    "                    fallback_data.append({\n",
    "                        \"session\": session_id,\n",
    "                        \"type\": event_type,\n",
    "                        \"aid\": aid\n",
    "                    })\n",
    "\n",
    "        test_candidates = pl.DataFrame(fallback_data)\n",
    "        log(f\"Emergency fallback candidates created: {len(test_candidates):,} candidates\")\n",
    "\n",
    "    except Exception as fallback_error:\n",
    "        log(f\"Even fallback candidate generation failed: {fallback_error}\")\n",
    "        # Create absolute minimal candidates\n",
    "        test_candidates = pl.DataFrame({\n",
    "            \"session\": [1, 1, 1],\n",
    "            \"type\": [\"clicks\", \"carts\", \"orders\"],\n",
    "            \"aid\": [1, 2, 3]\n",
    "        })\n",
    "        log(\"Created minimal test candidates to prevent complete failure\")\n",
    "\n",
    "log(f\"Final candidate count: {len(test_candidates):,}\")\n",
    "monitor_memory(\"after candidate generation\", force_cleanup=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mZze72GTQBRM"
   },
   "source": [
    "## CANDIDATE ANALYSIS AND STATISTICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tUHEZdo-QDbU",
    "outputId": "bd83a9d6-02fd-42ac-93c0-f8cd09b1107d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:22:50] [13.4GB] Analyzing generated candidates...\n",
      "[2025-08-07 21:22:52] [14.4GB]    Basic Stats:\n",
      "[2025-08-07 21:22:52] [14.3GB]    Total candidates: 95,687,062\n",
      "[2025-08-07 21:22:52] [14.3GB]    Unique sessions: 1,671,803\n",
      "[2025-08-07 21:22:52] [14.2GB]    Unique items: 703,050\n",
      "[2025-08-07 21:22:52] [14.2GB]    Per-Type Analysis:\n",
      "[2025-08-07 21:22:52] [15.1GB]    clicks: 37,235,896 candidates, 1,671,803 sessions, 22.3 avg/session\n",
      "[2025-08-07 21:22:53] [14.9GB]    carts: 29,225,562 candidates, 1,671,803 sessions, 17.5 avg/session\n",
      "[2025-08-07 21:22:54] [14.8GB]    orders: 29,225,604 candidates, 1,671,803 sessions, 17.5 avg/session\n",
      "[2025-08-07 21:22:54] [13.9GB]    Coverage Analysis:\n",
      "[2025-08-07 21:22:54] [13.9GB]    Test sessions covered: 1,671,803 / 1,671,803 (100.0%)\n",
      "[2025-08-07 21:22:55] [14.1GB]    Top 10 Most Frequent Candidate Items:\n",
      "[2025-08-07 21:22:55] [14.1GB]     1. Item 828731: 5,015,409 times\n",
      "[2025-08-07 21:22:55] [14.1GB]     2. Item 103562: 5,015,409 times\n",
      "[2025-08-07 21:22:55] [14.0GB]     3. Item 448043: 5,015,409 times\n",
      "[2025-08-07 21:22:55] [14.0GB]     4. Item 1202276: 5,015,409 times\n",
      "[2025-08-07 21:22:55] [14.0GB]     5. Item 1278837: 5,015,409 times\n",
      "[2025-08-07 21:22:55] [13.9GB]     6. Item 1790844: 5,015,409 times\n",
      "[2025-08-07 21:22:55] [13.9GB]     7. Item 513737: 5,015,409 times\n",
      "[2025-08-07 21:22:55] [13.9GB]     8. Item 1574011: 5,015,409 times\n",
      "[2025-08-07 21:22:55] [13.9GB]     9. Item 983011: 5,015,409 times\n",
      "[2025-08-07 21:22:55] [13.9GB]    10. Item 1411865: 3,343,631 times\n",
      "[2025-08-07 21:22:57] [14.2GB]    Candidate Distribution per Session-Type:\n",
      "[2025-08-07 21:22:57] [14.2GB]    Min: 15, Max: 28, Avg: 19.1, Median: 18.0\n",
      "   Memory cleanup triggered at 14.0GB during final statistics compilation\n",
      "   Memory after cleanup: 14.0GB\n",
      "[2025-08-07 21:23:00] [14.0GB] Candidate analysis completed!\n"
     ]
    }
   ],
   "source": [
    "def analyze_generated_candidates(candidates_df: pl.DataFrame,\n",
    "                               test_df: pl.DataFrame) -> Dict:\n",
    "    \"\"\"\n",
    "    Analyze the generated candidates and create statistics with memory efficiency\n",
    "\n",
    "    Args:\n",
    "        candidates_df: Generated candidates\n",
    "        test_df: Original test data\n",
    "\n",
    "    Returns:\n",
    "        dict: Comprehensive statistics about the candidates\n",
    "    \"\"\"\n",
    "    log(\"Analyzing generated candidates...\")\n",
    "\n",
    "    # Input validation\n",
    "    if candidates_df is None:\n",
    "        raise ValueError(\"candidates_df is None\")\n",
    "\n",
    "    if len(candidates_df) == 0:\n",
    "        log(\"   Warning: Empty candidates DataFrame\")\n",
    "        return {\n",
    "            \"generation_timestamp\": datetime.now().isoformat(),\n",
    "            \"error\": \"No candidates to analyze\",\n",
    "            \"total_candidates\": 0,\n",
    "            \"unique_sessions\": 0,\n",
    "            \"unique_items\": 0\n",
    "        }\n",
    "\n",
    "    # Verify required columns exist\n",
    "    required_columns = ['session', 'type', 'aid']\n",
    "    missing_columns = [col for col in required_columns if col not in candidates_df.columns]\n",
    "    if missing_columns:\n",
    "        raise ValueError(f\"candidates_df missing required columns: {missing_columns}\")\n",
    "\n",
    "    # Basic statistics\n",
    "    total_candidates = len(candidates_df)\n",
    "    unique_sessions = candidates_df.select(\"session\").n_unique()\n",
    "    unique_items = candidates_df.select(\"aid\").n_unique()\n",
    "\n",
    "    log(f\"   Basic Stats:\")\n",
    "    log(f\"   Total candidates: {total_candidates:,}\")\n",
    "    log(f\"   Unique sessions: {unique_sessions:,}\")\n",
    "    log(f\"   Unique items: {unique_items:,}\")\n",
    "\n",
    "    # Per-type analysis\n",
    "    log(f\"   Per-Type Analysis:\")\n",
    "    type_stats = {}\n",
    "\n",
    "    for event_type in [\"clicks\", \"carts\", \"orders\"]:\n",
    "        type_data = candidates_df.filter(pl.col(\"type\") == event_type)\n",
    "        type_sessions = type_data.select(\"session\").n_unique()\n",
    "        type_candidates = len(type_data)\n",
    "        avg_per_session = type_candidates / type_sessions if type_sessions > 0 else 0\n",
    "\n",
    "        type_stats[event_type] = {\n",
    "            \"total_candidates\": type_candidates,\n",
    "            \"unique_sessions\": type_sessions,\n",
    "            \"avg_candidates_per_session\": avg_per_session\n",
    "        }\n",
    "\n",
    "        log(f\"   {event_type}: {type_candidates:,} candidates, {type_sessions:,} sessions, {avg_per_session:.1f} avg/session\")\n",
    "\n",
    "        # Clean up intermediate data\n",
    "        del type_data\n",
    "\n",
    "    monitor_memory(\"type analysis\")\n",
    "\n",
    "    # Coverage analysis\n",
    "    test_sessions_total = test_df.select(\"session\").n_unique()\n",
    "    coverage_pct = (unique_sessions / test_sessions_total) * 100 if test_sessions_total > 0 else 0\n",
    "\n",
    "    log(f\"   Coverage Analysis:\")\n",
    "    log(f\"   Test sessions covered: {unique_sessions:,} / {test_sessions_total:,} ({coverage_pct:.1f}%)\")\n",
    "\n",
    "    # Item popularity in candidates (memory efficient)\n",
    "    try:\n",
    "        item_frequency = candidates_df.group_by(\"aid\").agg([\n",
    "            pl.count().alias(\"frequency\")\n",
    "        ]).sort(\"frequency\", descending=True)\n",
    "\n",
    "        top_items = item_frequency.head(10)\n",
    "        log(f\"   Top 10 Most Frequent Candidate Items:\")\n",
    "        for i, row in enumerate(top_items.iter_rows(), 1):\n",
    "            aid, freq = row\n",
    "            log(f\"   {i:2d}. Item {aid}: {freq:,} times\")\n",
    "\n",
    "        # Clean up\n",
    "        del item_frequency\n",
    "\n",
    "    except Exception as e:\n",
    "        log(f\"   Could not analyze item frequency: {e}\")\n",
    "        top_items = pl.DataFrame({\"aid\": [], \"frequency\": []})\n",
    "\n",
    "    monitor_memory(\"item frequency analysis\")\n",
    "\n",
    "    # Candidate distribution analysis\n",
    "    try:\n",
    "        session_candidate_counts = candidates_df.group_by([\"session\", \"type\"]).agg([\n",
    "            pl.count().alias(\"candidate_count\")\n",
    "        ])\n",
    "\n",
    "        if len(session_candidate_counts) > 0:\n",
    "            dist_stats = session_candidate_counts.select([\n",
    "                pl.col(\"candidate_count\").min().alias(\"min_candidates\"),\n",
    "                pl.col(\"candidate_count\").max().alias(\"max_candidates\"),\n",
    "                pl.col(\"candidate_count\").mean().alias(\"avg_candidates\"),\n",
    "                pl.col(\"candidate_count\").median().alias(\"median_candidates\")\n",
    "            ])\n",
    "\n",
    "            log(f\"   Candidate Distribution per Session-Type:\")\n",
    "            for row in dist_stats.iter_rows():\n",
    "                min_c, max_c, avg_c, med_c = row\n",
    "                log(f\"   Min: {min_c}, Max: {max_c}, Avg: {avg_c:.1f}, Median: {med_c:.1f}\")\n",
    "\n",
    "            # Extract values for the statistics dictionary\n",
    "            min_candidates = int(dist_stats.select(\"min_candidates\").item())\n",
    "            max_candidates = int(dist_stats.select(\"max_candidates\").item())\n",
    "            avg_candidates = float(dist_stats.select(\"avg_candidates\").item())\n",
    "            median_candidates = float(dist_stats.select(\"median_candidates\").item())\n",
    "\n",
    "            # Clean up\n",
    "            del session_candidate_counts, dist_stats\n",
    "        else:\n",
    "            log(f\"   No session-type combinations found for distribution analysis\")\n",
    "            min_candidates = max_candidates = avg_candidates = median_candidates = 0\n",
    "\n",
    "    except Exception as e:\n",
    "        log(f\"   Could not analyze candidate distribution: {e}\")\n",
    "        min_candidates = max_candidates = avg_candidates = median_candidates = 0\n",
    "\n",
    "    monitor_memory(\"distribution analysis\")\n",
    "\n",
    "    # Compile final statistics\n",
    "    statistics = {\n",
    "        \"generation_timestamp\": datetime.now().isoformat(),\n",
    "        \"total_candidates\": total_candidates,\n",
    "        \"unique_sessions\": unique_sessions,\n",
    "        \"unique_items\": unique_items,\n",
    "        \"test_sessions_total\": test_sessions_total,\n",
    "        \"coverage_percentage\": coverage_pct,\n",
    "        \"type_statistics\": type_stats,\n",
    "        \"distribution_stats\": {\n",
    "            \"min_candidates_per_session_type\": min_candidates,\n",
    "            \"max_candidates_per_session_type\": max_candidates,\n",
    "            \"avg_candidates_per_session_type\": avg_candidates,\n",
    "            \"median_candidates_per_session_type\": median_candidates\n",
    "        },\n",
    "        \"top_candidate_items\": [\n",
    "            {\"aid\": int(row[0]), \"frequency\": int(row[1])}\n",
    "            for row in top_items.iter_rows()\n",
    "        ] if len(top_items) > 0 else []\n",
    "    }\n",
    "\n",
    "    # Clean up\n",
    "    del top_items\n",
    "    monitor_memory(\"final statistics compilation\", force_cleanup=True)\n",
    "\n",
    "    log(\"Candidate analysis completed!\")\n",
    "    return statistics\n",
    "\n",
    "# Analyze candidates\n",
    "candidate_statistics = analyze_generated_candidates(test_candidates, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7D0bkIszQIg8"
   },
   "source": [
    "## SAVE OUTPUTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1ajf0kJCQKVc",
    "outputId": "df2ea45c-97c9-4b39-fdf6-2f1127c78428"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:23:00] [14.0GB] Saving outputs...\n",
      "[2025-08-07 21:23:14] [13.5GB]    test_candidates.parquet saved (72.0 MB)\n",
      "[2025-08-07 21:23:14] [13.5GB]    candidate_statistics.json saved\n",
      "[2025-08-07 21:23:14] [13.5GB]    input_validation_2b1.json saved\n",
      "[2025-08-07 21:23:14] [13.5GB]    part_2b1_summary.json saved\n",
      "[2025-08-07 21:23:14] [13.5GB] All outputs saved successfully!\n"
     ]
    }
   ],
   "source": [
    "def save_outputs(candidates_df: pl.DataFrame,\n",
    "                statistics: Dict,\n",
    "                validation_results: Dict):\n",
    "    \"\"\"\n",
    "    Save all outputs from this notebook with memory efficiency\n",
    "\n",
    "    Args:\n",
    "        candidates_df: Generated candidates\n",
    "        statistics: Candidate statistics\n",
    "        validation_results: Input validation results\n",
    "    \"\"\"\n",
    "    log(\"Saving outputs...\")\n",
    "\n",
    "    try:\n",
    "        # 1. Save test candidates (main output)\n",
    "        candidates_path = f\"{config.OUTPUT_PATH}/test_candidates.parquet\"\n",
    "        candidates_df.write_parquet(candidates_path)\n",
    "        file_size = os.path.getsize(candidates_path) / (1024*1024)\n",
    "        log(f\"   test_candidates.parquet saved ({file_size:.1f} MB)\")\n",
    "\n",
    "        # 2. Save candidate statistics\n",
    "        stats_path = f\"{config.OUTPUT_PATH}/candidate_statistics.json\"\n",
    "        with open(stats_path, \"w\") as f:\n",
    "            json.dump(statistics, f, indent=2)\n",
    "        log(f\"   candidate_statistics.json saved\")\n",
    "\n",
    "        # 3. Save validation results\n",
    "        validation_path = f\"{config.OUTPUT_PATH}/input_validation_2b1.json\"\n",
    "        with open(validation_path, \"w\") as f:\n",
    "            json.dump(validation_results, f, indent=2)\n",
    "        log(f\"   input_validation_2b1.json saved\")\n",
    "\n",
    "        # 4. Save a summary report\n",
    "        summary = {\n",
    "            \"notebook\": \"Part 2B1: Test Candidate Generation (Memory Optimized)\",\n",
    "            \"completion_timestamp\": datetime.now().isoformat(),\n",
    "            \"inputs_used\": {\n",
    "                \"test_clean.parquet\": f\"{test_df.shape[0]:,} events, {test_df.select('session').n_unique():,} sessions\",\n",
    "                \"item_stats.parquet\": f\"{item_stats.shape[0]:,} items\",\n",
    "                \"consolidated_covisitation_matrices.pkl\": f\"{validation_results['total_source_items']:,} source items, {validation_results['total_pairs']:,} pairs\"\n",
    "            },\n",
    "            \"outputs_generated\": {\n",
    "                \"test_candidates.parquet\": f\"{len(candidates_df):,} candidates\",\n",
    "                \"candidate_statistics.json\": \"Detailed candidate analysis\",\n",
    "                \"input_validation_2b1.json\": \"Input validation results\"\n",
    "            },\n",
    "            \"key_metrics\": {\n",
    "                \"total_candidates\": statistics[\"total_candidates\"],\n",
    "                \"coverage_percentage\": statistics[\"coverage_percentage\"],\n",
    "                \"avg_candidates_per_session_type\": statistics[\"distribution_stats\"][\"avg_candidates_per_session_type\"],\n",
    "                \"memory_optimization\": \"Enabled - chunked processing, immediate cleanup, progress monitoring\"\n",
    "            },\n",
    "            \"performance_notes\": {\n",
    "                \"chunk_size\": config.CHUNK_SIZE,\n",
    "                \"max_memory_gb\": config.MAX_MEMORY_GB,\n",
    "                \"gc_frequency\": config.GC_FREQUENCY\n",
    "            },\n",
    "            \"next_step\": \"Run Part 2B2: Training Data Preparation\"\n",
    "        }\n",
    "\n",
    "        summary_path = f\"{config.OUTPUT_PATH}/part_2b1_summary.json\"\n",
    "        with open(summary_path, \"w\") as f:\n",
    "            json.dump(summary, f, indent=2)\n",
    "        log(f\"   part_2b1_summary.json saved\")\n",
    "\n",
    "        log(\"All outputs saved successfully!\")\n",
    "\n",
    "        return {\n",
    "            \"candidates_path\": candidates_path,\n",
    "            \"statistics_path\": stats_path,\n",
    "            \"validation_path\": validation_path,\n",
    "            \"summary_path\": summary_path\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        log(f\"Error saving outputs: {e}\")\n",
    "        raise e\n",
    "\n",
    "# Save all outputs\n",
    "output_paths = save_outputs(test_candidates, candidate_statistics, validation_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "33gfHYh6QNA3"
   },
   "source": [
    "## FINAL SUMMARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wUr96rheQPIi",
    "outputId": "e07f1ada-070c-456b-db1d-eee2a0b12dd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-07 21:23:14] [13.4GB] \n",
      "================================================================================\n",
      "[2025-08-07 21:23:14] [13.4GB] PART 2B1 COMPLETED: TEST CANDIDATE GENERATION (MEMORY OPTIMIZED)\n",
      "[2025-08-07 21:23:14] [13.4GB] ================================================================================\n",
      "[2025-08-07 21:23:14] [13.4GB] \n",
      "KEY RESULTS:\n",
      "[2025-08-07 21:23:14] [13.4GB] Total candidates generated: 95,687,062\n",
      "[2025-08-07 21:23:14] [13.4GB] Test sessions covered: 1,671,803 / 1,671,803 (100.0%)\n",
      "[2025-08-07 21:23:14] [13.4GB] Average candidates per session-type: 19.1\n",
      "[2025-08-07 21:23:14] [13.4GB] Unique items in candidates: 703,050\n",
      "[2025-08-07 21:23:14] [13.4GB] \n",
      "OUTPUT FILES GENERATED:\n",
      "[2025-08-07 21:23:14] [13.4GB] test_candidates.parquet (72.0 MB)\n",
      "[2025-08-07 21:23:14] [13.4GB] candidate_statistics.json (0.0 MB)\n",
      "[2025-08-07 21:23:14] [13.4GB] input_validation_2b1.json (0.0 MB)\n",
      "[2025-08-07 21:23:14] [13.4GB] part_2b1_summary.json (0.0 MB)\n",
      "[2025-08-07 21:23:14] [13.4GB] All files saved to: /content/drive/MyDrive/Colab Notebooks/CML/Assignment 1/content/otto-output\n",
      "[2025-08-07 21:23:14] [13.4GB] \n",
      "PERFORMANCE METRICS:\n",
      "[2025-08-07 21:23:14] [13.4GB] Final memory usage: 13.4 GB\n",
      "[2025-08-07 21:23:14] [13.4GB] Chunk size used: 2,500 sessions\n",
      "[2025-08-07 21:23:14] [13.4GB] Memory optimization: ENABLED\n",
      "[2025-08-07 21:23:14] [13.4GB] \n",
      "QUALITY CHECK:\n",
      "[2025-08-07 21:23:14] [13.4GB] Coverage ≥ 95%: yes (100.0%)\n",
      "[2025-08-07 21:23:14] [13.4GB] Avg candidates ≥ 50: no (19.1)\n",
      "[2025-08-07 21:23:14] [13.4GB] Total candidates ≥ 100K: yes (95,687,062)\n",
      "[2025-08-07 21:23:14] [13.4GB] \n",
      "Overall Quality: ACCEPTABLE\n",
      "[2025-08-07 21:23:14] [13.4GB] \n",
      "Performing final memory cleanup...\n",
      "[2025-08-07 21:23:14] [13.4GB]    test_df cleaned\n",
      "[2025-08-07 21:23:14] [13.4GB]    item_stats cleaned\n",
      "[2025-08-07 21:23:14] [13.4GB]    covisitation matrices cleaned\n",
      "[2025-08-07 21:23:15] [10.5GB]    test_candidates cleaned\n",
      "[2025-08-07 21:23:18] [0.9GB]    candidate function cleaned\n",
      "[2025-08-07 21:23:18] [0.9GB] Final memory usage after cleanup: 0.9 GB\n",
      "[2025-08-07 21:23:18] [0.9GB] \n",
      "Memory optimization completed successfully!\n",
      "[2025-08-07 21:23:18] [0.9GB] Part 2B1 finished successfully with enhanced memory efficiency!\n",
      "[2025-08-07 21:23:18] [0.9GB] ================================================================================\n"
     ]
    }
   ],
   "source": [
    "log(\"\\n\" + \"=\"*80)\n",
    "log(\"PART 2B1 COMPLETED: TEST CANDIDATE GENERATION (MEMORY OPTIMIZED)\")\n",
    "log(\"=\"*80)\n",
    "\n",
    "log(f\"\\nKEY RESULTS:\")\n",
    "log(f\"Total candidates generated: {candidate_statistics['total_candidates']:,}\")\n",
    "log(f\"Test sessions covered: {candidate_statistics['unique_sessions']:,} / {candidate_statistics['test_sessions_total']:,} ({candidate_statistics['coverage_percentage']:.1f}%)\")\n",
    "log(f\"Average candidates per session-type: {candidate_statistics['distribution_stats']['avg_candidates_per_session_type']:.1f}\")\n",
    "log(f\"Unique items in candidates: {candidate_statistics['unique_items']:,}\")\n",
    "\n",
    "log(f\"\\nOUTPUT FILES GENERATED:\")\n",
    "for description, path in output_paths.items():\n",
    "    file_size = os.path.getsize(path) / (1024*1024)\n",
    "    filename = os.path.basename(path)\n",
    "    log(f\"{filename} ({file_size:.1f} MB)\")\n",
    "log(f\"All files saved to: {config.OUTPUT_PATH}\")\n",
    "\n",
    "log(f\"\\nPERFORMANCE METRICS:\")\n",
    "log(f\"Final memory usage: {get_memory_usage():.1f} GB\")\n",
    "log(f\"Chunk size used: {config.CHUNK_SIZE:,} sessions\")\n",
    "log(f\"Memory optimization: ENABLED\")\n",
    "\n",
    "log(f\"\\nQUALITY CHECK:\")\n",
    "coverage_ok = candidate_statistics['coverage_percentage'] > 95\n",
    "avg_candidates_ok = candidate_statistics['distribution_stats']['avg_candidates_per_session_type'] > 50\n",
    "total_candidates_ok = candidate_statistics['total_candidates'] > 100000  # Adjusted threshold\n",
    "\n",
    "log(f\"Coverage ≥ 95%: {'yes' if coverage_ok else 'no'} ({candidate_statistics['coverage_percentage']:.1f}%)\")\n",
    "log(f\"Avg candidates ≥ 50: {'yes' if avg_candidates_ok else 'no'} ({candidate_statistics['distribution_stats']['avg_candidates_per_session_type']:.1f})\")\n",
    "log(f\"Total candidates ≥ 100K: {'yes' if total_candidates_ok else 'no'} ({candidate_statistics['total_candidates']:,})\")\n",
    "\n",
    "overall_quality = \"EXCELLENT\" if all([coverage_ok, avg_candidates_ok, total_candidates_ok]) else \"ACCEPTABLE\"\n",
    "log(f\"\\nOverall Quality: {overall_quality}\")\n",
    "\n",
    "# Clean up memory - moved all large objects\n",
    "log(\"\\nPerforming final memory cleanup...\")\n",
    "try:\n",
    "    del test_df\n",
    "    log(\"   test_df cleaned\")\n",
    "except: pass\n",
    "\n",
    "try:\n",
    "    del item_stats\n",
    "    log(\"   item_stats cleaned\")\n",
    "except: pass\n",
    "\n",
    "try:\n",
    "    del consolidated_covisitation_matrices\n",
    "    log(\"   covisitation matrices cleaned\")\n",
    "except: pass\n",
    "\n",
    "try:\n",
    "    del test_candidates\n",
    "    log(\"   test_candidates cleaned\")\n",
    "except: pass\n",
    "\n",
    "try:\n",
    "    del generate_candidates_func\n",
    "    log(\"   candidate function cleaned\")\n",
    "except: pass\n",
    "\n",
    "# Final garbage collection\n",
    "memory_cleanup()\n",
    "final_memory = get_memory_usage()\n",
    "log(f\"Final memory usage after cleanup: {final_memory:.1f} GB\")\n",
    "\n",
    "log(f\"\\nMemory optimization completed successfully!\")\n",
    "log(f\"Part 2B1 finished successfully with enhanced memory efficiency!\")\n",
    "log(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
